#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script Î³Î¹Î± Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Ï‰Î½ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÏÎ½ JSON datasets ÏƒÎµ IOB format
Î£Ï…Î¼Î²Î±Î´Î¯Î¶ÎµÎ¹ Î¼Îµ Ï„Î· Î»Î¿Î³Î¹ÎºÎ® Ï„Î¿Ï… count_labels.py
"""

import json
import os

def load_label_mapping(mapping_file):
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ mapping Î±ÏÎ¹Î¸Î¼ÏÎ½ ÏƒÎµ Î¿Î½ÏŒÎ¼Î±Ï„Î± labels
    """
    try:
        with open(mapping_file, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
        
        # Î‘Î½Ï„Î¹ÏƒÏ„ÏÎ¿Ï†Î® Ï„Î¿Ï… mapping (Î±Ï€ÏŒ ÏŒÎ½Î¿Î¼Î± -> Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ ÏƒÎµ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ -> ÏŒÎ½Î¿Î¼Î±)
        reverse_mapping = {str(v): k for k, v in mapping.items()}
        return reverse_mapping
    except Exception as e:
        print(f"Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ mapping: {e}")
        return {}

def convert_numeric_to_iob_labels(labels_list, label_mapping):
    """
    ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¬ labels ÏƒÎµ IOB format Î¼Îµ Î¿Î½ÏŒÎ¼Î±Ï„Î±
    Î™Î”Î™Î‘ Î›ÎŸÎ“Î™ÎšÎ— ÎœÎ• count_labels.py
    
    Args:
        labels_list (list): Lista Î¼Îµ Ï„Î± Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¬ labels Î¼Î¹Î±Ï‚ Ï€ÏÏŒÏ„Î±ÏƒÎ·Ï‚
        label_mapping (dict): Mapping Î±Ï€ÏŒ Î±ÏÎ¹Î¸Î¼ÏŒ ÏƒÎµ ÏŒÎ½Î¿Î¼Î±
        
    Returns:
        list: Lista Î¼Îµ IOB tags Î¼Îµ Î¿Î½ÏŒÎ¼Î±Ï„Î±
    """
    iob_tags = []
    
    for i, label in enumerate(labels_list):
        label_str = str(label)
        
        if label_str == '0':
            iob_tags.append('O')
        else:
            # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… label Î±Ï€ÏŒ Ï„Î¿ mapping
            label_name = label_mapping.get(label_str, f'UNKNOWN_{label}')
            
            # Î‘Î½ Ï„Î¿ label Î®Î´Î· Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ B- Î® I-, Ï„Î¿ ÎºÏÎ±Ï„Î¬Î¼Îµ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹
            if label_name.startswith('B-') or label_name.startswith('I-'):
                iob_tags.append(label_name)
            else:
                # Î‘Î»Î»Î¹ÏÏ‚, ÎºÎ±Î¸Î¿ÏÎ¯Î¶Î¿Ï…Î¼Îµ Î±Î½ ÎµÎ¯Î½Î±Î¹ B- Î® I- Î²Î¬ÏƒÎµÎ¹ Ï„Î·Ï‚ Î¸Î­ÏƒÎ·Ï‚
                if i == 0 or str(labels_list[i-1]) != label_str:
                    iob_tags.append(f'B-{label_name}')
                else:
                    iob_tags.append(f'I-{label_name}')
    
    return iob_tags

def convert_dataset_to_iob(input_file, output_file, label_mapping):
    """
    ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Î­Î½Î± dataset Î±Ï€ÏŒ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¬ labels ÏƒÎµ IOB format
    """
    print(f"ÎœÎµÏ„Î±Ï„ÏÎ­Ï€Ï‰ {input_file} -> {output_file}")
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Î¿Ï… Î±ÏÏ‡Î¹ÎºÎ¿Ï dataset
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Î•Î¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    inputs = data.get('input', [])
    numeric_labels = data.get('label', [])
    languages = data.get('language', ['el'] * len(inputs))  # Default ÏƒÎµ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
    
    print(f"  - Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(inputs)} Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚")
    print(f"  - Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(numeric_labels)} label sequences")
    
    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® labels ÏƒÎµ IOB format
    iob_labels = []
    total_tokens = 0
    
    for sentence_labels in numeric_labels:
        iob_tags = convert_numeric_to_iob_labels(sentence_labels, label_mapping)
        iob_labels.append(iob_tags)
        total_tokens += len(sentence_labels)
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Î¿Ï… dataset
    iob_dataset = {
        "input": inputs,
        "label": iob_labels,
        "language": languages
    }
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(iob_dataset, f, ensure_ascii=False, indent=2)
    
    print(f"  âœ… Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î¼Îµ {total_tokens} tokens")
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÏƒÏ…Î½Î­Ï€ÎµÎ¹Î±Ï‚
    assert len(inputs) == len(iob_labels), "Mismatch ÏƒÎµ Î±ÏÎ¹Î¸Î¼ÏŒ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÏ‰Î½!"
    for i, (tokens, labels) in enumerate(zip(inputs, iob_labels)):
        assert len(tokens) == len(labels), f"Mismatch ÏƒÎµ Ï€ÏÏŒÏ„Î±ÏƒÎ· {i}: {len(tokens)} tokens vs {len(labels)} labels"
    
    print(f"  âœ… ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÏƒÏ…Î½Î­Ï€ÎµÎ¹Î±Ï‚: OK")
    
    # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ IOB labels
    all_iob_labels = [label for sentence in iob_labels for label in sentence]
    unique_labels = set(all_iob_labels)
    print(f"  ğŸ“Š Unique IOB labels: {len(unique_labels)}")
    print(f"     {sorted(unique_labels)}")
    
    return len(unique_labels), total_tokens

def validate_iob_format(iob_labels):
    """
    Î•Î»Î­Î³Ï‡ÎµÎ¹ Î±Î½ Ï„Î± IOB labels ÎµÎ¯Î½Î±Î¹ ÏƒÏ‰ÏƒÏ„Î¬ ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼Î­Î½Î±
    """
    errors = []
    
    for sentence_idx, sentence_labels in enumerate(iob_labels):
        for token_idx, label in enumerate(sentence_labels):
            if label.startswith('I-'):
                # Î•Î»Î­Î³Ï‡ÎµÎ¹ Î±Î½ Ï„Î¿ I- Î±ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿ B- Î® I-
                if token_idx == 0:
                    errors.append(f"Sentence {sentence_idx}, Token {token_idx}: I- tag at start of sentence")
                else:
                    prev_label = sentence_labels[token_idx - 1]
                    entity_type = label[2:]  # Î‘Ï†Î±Î¹ÏÎµÎ¯ Ï„Î¿ 'I-'
                    
                    if prev_label == 'O':
                        errors.append(f"Sentence {sentence_idx}, Token {token_idx}: I-{entity_type} after O")
                    elif prev_label.startswith('B-') or prev_label.startswith('I-'):
                        prev_entity_type = prev_label[2:]
                        if prev_entity_type != entity_type:
                            errors.append(f"Sentence {sentence_idx}, Token {token_idx}: I-{entity_type} after {prev_label}")
    
    return errors

# Paths - Î”Î™ÎŸÎ¡Î˜Î©ÎœÎ•ÎÎ‘ PATHS
script_dir = os.path.dirname(os.path.abspath(__file__))
base_path = script_dir  # Î¤Î¿ script ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ„Î¿Î½ GREEK_LEGAL_NER Ï†Î¬ÎºÎµÎ»Î¿
code_dir = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))  # Î Î¬Î¼Îµ ÏƒÏ„Î¿ CODE directory
mapping_file = os.path.join(code_dir, "greek_legal_ner_label_mapping.json")

# Datasets Î³Î¹Î± Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î®
datasets = {
    "train": {
        "input": os.path.join(base_path, "train.json"),
        "output": os.path.join(base_path, "train_iob.json")
    },
    "test": {
        "input": os.path.join(base_path, "test.json"),
        "output": os.path.join(base_path, "test_iob.json")
    },
    "validation": {
        "input": os.path.join(base_path, "validation.json"),
        "output": os.path.join(base_path, "validation_iob.json")
    }
}

print("="*80)
print("ÎœÎ•Î¤Î‘Î¤Î¡ÎŸÎ Î— DATASETS Î£Î• IOB FORMAT")
print("="*80)

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· mapping
fallback_mappings = [
    "greek_legal_ner_label_mapping.json",  # Î£Îµ current directory
    "../../greek_legal_ner_label_mapping.json",  # Î”ÏÎ¿ ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï€Î¬Î½Ï‰
    "../../../greek_legal_ner_label_mapping.json"  # Î¤ÏÎ¯Î± ÎµÏ€Î¯Ï€ÎµÎ´Î± Ï€Î¬Î½Ï‰
]

label_mapping = {}
for mapping_path in [mapping_file] + fallback_mappings:
    try:
        label_mapping = load_label_mapping(mapping_path)
        if label_mapping:
            print(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ mapping ÏƒÏ„Î¿: {mapping_path}")
            break
    except:
        continue

if not label_mapping:
    print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ label mapping ÏƒÎµ ÎºÎ±Î½Î­Î½Î± Î±Ï€ÏŒ Ï„Î± paths!")
    for path in [mapping_file] + fallback_mappings:
        print(f"   Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Î·ÎºÎµ: {path}")
    exit(1)

print(f"âœ… Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ mapping Î³Î¹Î± {len(label_mapping)} labels")
print(f"   Mapping: {label_mapping}")

# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ datasets
total_datasets = 0
total_tokens = 0
all_unique_labels = set()

for dataset_name, paths in datasets.items():
    if not os.path.exists(paths["input"]):
        print(f"âš ï¸  Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ {paths['input']} Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹! Î Î±ÏÎ±Î»ÎµÎ¯Ï€ÎµÏ„Î±Î¹...")
        continue
    
    try:
        unique_labels_count, token_count = convert_dataset_to_iob(
            paths["input"], 
            paths["output"], 
            label_mapping
        )
        total_datasets += 1
        total_tokens += token_count
        
        # Î£Ï…Î»Î»Î¿Î³Î® unique labels Î³Î¹Î± validation
        with open(paths["output"], 'r', encoding='utf-8') as f:
            iob_data = json.load(f)
        
        dataset_labels = [label for sentence in iob_data["label"] for label in sentence]
        all_unique_labels.update(dataset_labels)
        
    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î· Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Î¿Ï… {dataset_name}: {e}")

# Î£Ï…Î½Î¿Î»Î¹ÎºÏŒÏ‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚
print("\n" + "="*80)
print("Î£Î¥ÎÎŸÎ¨Î— ÎœÎ•Î¤Î‘Î¤Î¡ÎŸÎ Î—Î£")
print("="*80)
print(f"âœ… ÎœÎµÏ„Î±Ï„ÏÎ¬Ï€Î·ÎºÎ±Î½ {total_datasets} datasets")
print(f"ğŸ“Š Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ tokens: {total_tokens:,}")
print(f"ğŸ·ï¸  Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ unique IOB labels: {len(all_unique_labels)}")

print("\nğŸ“‹ ÎŒÎ»Î± Ï„Î± IOB labels:")
for label in sorted(all_unique_labels):
    print(f"   {label}")

# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ IOB format correctness
print("\nğŸ” ÎˆÎ›Î•Î“Î§ÎŸÎ£ IOB FORMAT CORRECTNESS:")
all_errors = []

for dataset_name, paths in datasets.items():
    if os.path.exists(paths["output"]):
        with open(paths["output"], 'r', encoding='utf-8') as f:
            iob_data = json.load(f)
        
        errors = validate_iob_format(iob_data["label"])
        if errors:
            print(f"âŒ {dataset_name}: {len(errors)} errors found")
            all_errors.extend(errors)
        else:
            print(f"âœ… {dataset_name}: No IOB format errors")

if all_errors:
    print(f"\nâš ï¸  Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ {len(all_errors)} IOB format errors:")
    for error in all_errors[:10]:  # Show first 10 errors
        print(f"   {error}")
    if len(all_errors) > 10:
        print(f"   ... ÎºÎ±Î¹ {len(all_errors) - 10} Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ±")
else:
    print(f"\nâœ… ÎŒÎ»Î± Ï„Î± datasets Î­Ï‡Î¿Ï…Î½ ÏƒÏ‰ÏƒÏ„ÏŒ IOB format!")

# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ consistency Î¼Îµ Ï„Î¿ ML model
print("\nğŸ¤– ÎˆÎ›Î•Î“Î§ÎŸÎ£ CONSISTENCY ÎœÎ• ML MODEL:")

for dataset_name, paths in datasets.items():
    if os.path.exists(paths["output"]):
        with open(paths["output"], 'r', encoding='utf-8') as f:
            iob_data = json.load(f)
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î´Î¿Î¼Î®Ï‚
        required_keys = ["input", "label", "language"]
        missing_keys = [key for key in required_keys if key not in iob_data]
        
        if missing_keys:
            print(f"âŒ {dataset_name}: Î›ÎµÎ¯Ï€Î¿Ï…Î½ keys: {missing_keys}")
        else:
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î¼ÎµÎ³ÎµÎ¸ÏÎ½
            input_len = len(iob_data["input"])
            label_len = len(iob_data["label"])
            lang_len = len(iob_data["language"])
            
            if input_len == label_len == lang_len:
                print(f"âœ… {dataset_name}: Î£Ï‰ÏƒÏ„Î® Î´Î¿Î¼Î® ({input_len} Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚)")
            else:
                print(f"âŒ {dataset_name}: Mismatch - input:{input_len}, label:{label_len}, lang:{lang_len}")

print("="*80)
print("ÎœÎ•Î¤Î‘Î¤Î¡ÎŸÎ Î— ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ•!")
print("="*80)
