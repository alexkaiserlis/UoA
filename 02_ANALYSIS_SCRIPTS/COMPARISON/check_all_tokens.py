#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Î· Î´Î¹Î±Ï†Î¿ÏÎ¬ Î¿Ï†ÎµÎ¯Î»ÎµÏ„Î±Î¹ ÏƒÏ„Î¿ ÏŒÏ„Î¹ Ï„Î¿ README Î¼ÎµÏ„ÏÎ¬ÎµÎ¹ B- + I- tags
"""

import json
import os
from collections import Counter

def count_all_entity_tokens():
    """
    ÎœÎµÏ„ÏÎ¬ÎµÎ¹ ÏŒÎ»Î± Ï„Î± entity tokens (B- + I-) Î±Î½Ï„Î¯ Î¼ÏŒÎ½Î¿ Ï„Î± B- (entities)
    """
    dataset_folder = r"C:\Users\User\Î¤Î¿ Drive Î¼Î¿Ï…\AEGEAN UNIVERSITY\LEGAL DOCUMENTS ARCHIVE\Î Î‘Î™Î“Î‘Î™ÎŸÎ¥\CODE\NER MODEL\GREEKLEGALNER DATASET"
    
    splits = {
        'train': 'train.jsonl',
        'validation': 'validation.jsonl', 
        'test': 'test.jsonl'
    }
    
    results = {}
    
    print("ğŸ” ÎœÎ•Î¤Î¡Î—Î£Î— ÎŸÎ›Î©Î Î¤Î©Î ENTITY TOKENS (B- + I- tags)")
    print("="*80)
    
    for split_name, filename in splits.items():
        file_path = os.path.join(dataset_folder, filename)
        
        if not os.path.exists(file_path):
            continue
        
        # Counters Î³Î¹Î± B- ÎºÎ±Î¹ I- tags
        entity_token_counts = Counter()
        
        # Î”Î¹Î¬Î²Î±ÏƒÎ¼Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    example = json.loads(line)
                    
                    if 'ner' in example:
                        for tag in example['ner']:
                            if tag.startswith('B-') or tag.startswith('I-'):
                                entity_type = tag[2:]  # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· B- Î® I-
                                entity_token_counts[entity_type] += 1
        
        results[split_name] = entity_token_counts
        
        total_entity_tokens = sum(entity_token_counts.values())
        print(f"\nğŸ“ {split_name.upper()} split:")
        print(f"  Î£ÏÎ½Î¿Î»Î¿ entity tokens (B- + I-): {total_entity_tokens:,}")
    
    return results

def compare_with_readme_all_tokens(our_results):
    """
    Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Î¼Îµ Ï„Î± ÎµÏ€Î¯ÏƒÎ·Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ ÏŒÎ»Î± Ï„Î± entity tokens
    """
    # Î•Ï€Î¯ÏƒÎ·Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€ÏŒ Ï„Î¿ README
    official_stats = {
        'FACILITY': {'train': 1224, 'validation': 60, 'test': 142},
        'GPE': {'train': 5400, 'validation': 1214, 'test': 1083},
        'LEG-REFS': {'train': 5159, 'validation': 1382, 'test': 1331},
        'LOCATION-NAT': {'train': 145, 'validation': 2, 'test': 26},
        'LOCATION-UNK': {'train': 1316, 'validation': 283, 'test': 205},
        'ORG': {'train': 5906, 'validation': 1506, 'test': 1354},
        'PERSON': {'train': 1921, 'validation': 475, 'test': 491},
        'PUBLIC-DOCS': {'train': 2652, 'validation': 556, 'test': 452}
    }
    
    print(f"\n" + "="*100)
    print("ğŸ“Š Î£Î¥Î“ÎšÎ¡Î™Î£Î— ÎœÎ• Î•Î Î™Î£Î—ÎœÎ‘ Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ‘ (ÎŒÎ»Î± Ï„Î± entity tokens)")
    print("="*100)
    
    print(f"{'ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±':<15} {'Split':<10} {'README':<10} {'B-+I- tags':<12} {'Î”Î¹Î±Ï†Î¿ÏÎ¬':<10} {'Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ':<10}")
    print("-" * 100)
    
    total_official = 0
    total_ours = 0
    
    for category in sorted(official_stats.keys()):
        for split in ['train', 'validation', 'test']:
            official_count = official_stats[category][split]
            our_count = our_results.get(split, {}).get(category, 0)
            
            difference = our_count - official_count
            percentage = (our_count / official_count * 100) if official_count > 0 else 0
            
            total_official += official_count
            total_ours += our_count
            
            print(f"{category:<15} {split:<10} {official_count:<10} {our_count:<12} {difference:<10} {percentage:<10.1f}%")
    
    print("-" * 100)
    total_diff = total_ours - total_official
    total_percentage = (total_ours / total_official * 100) if total_official > 0 else 0
    print(f"{'Î£Î¥ÎÎŸÎ›ÎŸ':<15} {'ALL':<10} {total_official:<10} {total_ours:<12} {total_diff:<10} {total_percentage:<10.1f}%")
    
    print(f"\nğŸ“Š Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘:")
    print(f"â€¢ Î•Ï€Î¯ÏƒÎ·Î¼Î±: {total_official:,}")
    print(f"â€¢ Î”Î¹ÎºÎ¬ Î¼Î±Ï‚ (B- + I-): {total_ours:,}")
    print(f"â€¢ Î‘ÎºÏÎ¯Î²ÎµÎ¹Î±: {total_percentage:.1f}%")
    
    if abs(total_percentage - 100) < 5:
        print("âœ… Î Î¿Î»Ï ÎºÎ¿Î½Ï„Î¬! Î— Î´Î¹Î±Ï†Î¿ÏÎ¬ Ï€Î¹Î¸Î±Î½ÏÏ‚ Î¿Ï†ÎµÎ¯Î»ÎµÏ„Î±Î¹ ÏƒÎµ Î¼Î¹ÎºÏÎ­Ï‚ Î±Î»Î»Î±Î³Î­Ï‚ ÏƒÏ„Î¿ dataset.")
    elif total_percentage > 95:
        print("âœ… Î£Ï‡ÎµÎ´ÏŒÎ½ Ï„Î±Ï…Ï„Î¯Î¶Î¿Î½Ï„Î±Î¹! ÎœÎ¹ÎºÏÎ­Ï‚ Î´Î¹Î±Ï†Î¿ÏÎ­Ï‚ ÎµÎ¯Î½Î±Î¹ Î±Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½ÎµÏ‚.")
    else:
        print("âš ï¸  Î•Î¾Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¿ÏÎ½ Î½Î± Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Ï†Î¿ÏÎ­Ï‚. Î Î¹Î¸Î±Î½ÏÏ‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ® Î­ÎºÎ´Î¿ÏƒÎ· dataset.")

if __name__ == "__main__":
    results = count_all_entity_tokens()
    compare_with_readme_all_tokens(results)
