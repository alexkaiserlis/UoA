#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Ï„Ï‰Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ Î¼Î±Ï‚ Î¼Îµ Ï„Î± ÎµÏ€Î¯ÏƒÎ·Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€ÏŒ Ï„Î¿ README
"""

# Î•Ï€Î¯ÏƒÎ·Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€ÏŒ Ï„Î¿ README
official_stats = {
    'FACILITY': {'train': 1224, 'validation': 60, 'test': 142},
    'GPE': {'train': 5400, 'validation': 1214, 'test': 1083},
    'LEG-REFS': {'train': 5159, 'validation': 1382, 'test': 1331},
    'LOCATION-NAT': {'train': 145, 'validation': 2, 'test': 26},
    'LOCATION-UNK': {'train': 1316, 'validation': 283, 'test': 205},
    'ORG': {'train': 5906, 'validation': 1506, 'test': 1354},
    'PERSON': {'train': 1921, 'validation': 475, 'test': 491},
    'PUBLIC-DOCS': {'train': 2652, 'validation': 556, 'test': 452}
}

# Î¤Î± Î´Î¹ÎºÎ¬ Î¼Î±Ï‚ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± (Î±Ï€ÏŒ Ï„Î·Î½ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· Î±Î½Î¬Î»Ï…ÏƒÎ·)
our_stats = {
    'FACILITY': {'train': 930, 'validation': 24, 'test': 87},
    'GPE': {'train': 3002, 'validation': 727, 'test': 586},
    'LEG-REFS': {'train': 1306, 'validation': 433, 'test': 419},
    'LOCATION-NAT': {'train': 18, 'validation': 1, 'test': 6},
    'LOCATION-UNK': {'train': 194, 'validation': 33, 'test': 34},
    'ORG': {'train': 2545, 'validation': 643, 'test': 518},
    'PERSON': {'train': 771, 'validation': 199, 'test': 242},
    'PUBLIC-DOCS': {'train': 620, 'validation': 132, 'test': 122}
}

def compare_statistics():
    """
    Î£Ï…Î³ÎºÏÎ¯Î½ÎµÎ¹ Ï„Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Î±Ï‚ Î¼Îµ Ï„Î± ÎµÏ€Î¯ÏƒÎ·Î¼Î±
    """
    print("ğŸ” Î£Î¥Î“ÎšÎ¡Î™Î£Î— Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ©Î: Î•Ï€Î¯ÏƒÎ·Î¼Î± README vs Î”Î¹ÎºÎ¬ Î¼Î±Ï‚ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±")
    print("="*100)
    
    print(f"{'ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±':<15} {'Split':<10} {'README':<10} {'Î”Î¹ÎºÎ¬ Î¼Î±Ï‚':<10} {'Î”Î¹Î±Ï†Î¿ÏÎ¬':<10} {'Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ':<10}")
    print("-" * 100)
    
    total_official = 0
    total_ours = 0
    
    for category in sorted(official_stats.keys()):
        for split in ['train', 'validation', 'test']:
            official_count = official_stats[category][split]
            our_count = our_stats[category][split]
            
            difference = our_count - official_count
            percentage = (our_count / official_count * 100) if official_count > 0 else 0
            
            total_official += official_count
            total_ours += our_count
            
            print(f"{category:<15} {split:<10} {official_count:<10} {our_count:<10} {difference:<10} {percentage:<10.1f}%")
    
    print("-" * 100)
    total_diff = total_ours - total_official
    total_percentage = (total_ours / total_official * 100) if total_official > 0 else 0
    print(f"{'Î£Î¥ÎÎŸÎ›ÎŸ':<15} {'ALL':<10} {total_official:<10} {total_ours:<10} {total_diff:<10} {total_percentage:<10.1f}%")
    
    print(f"\nğŸ“Š Î£Î¥ÎÎŸÎ Î¤Î™ÎšÎ‘ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘:")
    print(f"â€¢ Î•Ï€Î¯ÏƒÎ·Î¼Î± entities: {total_official:,}")
    print(f"â€¢ Î”Î¹ÎºÎ¬ Î¼Î±Ï‚ entities: {total_ours:,}")
    print(f"â€¢ Î”Î¹Î±Ï†Î¿ÏÎ¬: {total_diff:,} ({total_percentage:.1f}% Ï„Ï‰Î½ ÎµÏ€Î¯ÏƒÎ·Î¼Ï‰Î½)")
    
    if total_ours < total_official:
        reduction_percentage = ((total_official - total_ours) / total_official) * 100
        print(f"â€¢ ÎœÎµÎ¯Ï‰ÏƒÎ·: {reduction_percentage:.1f}%")
    
    # Î‘Î½Î¬Î»Ï…ÏƒÎ· Î±Î½Î¬ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±
    print(f"\nğŸ” Î‘ÎÎ‘Î›Î¥Î£Î— Î‘ÎÎ‘ ÎšÎ‘Î¤Î—Î“ÎŸÎ¡Î™Î‘:")
    for category in sorted(official_stats.keys()):
        official_total = sum(official_stats[category].values())
        our_total = sum(our_stats[category].values())
        reduction = ((official_total - our_total) / official_total) * 100 if official_total > 0 else 0
        
        print(f"â€¢ {category}: {our_total}/{official_total} ({100-reduction:.1f}% Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎ·)")

def analyze_potential_causes():
    """
    Î‘Î½Î±Î»ÏÎµÎ¹ Ï€Î¹Î¸Î±Î½Î­Ï‚ Î±Î¹Ï„Î¯ÎµÏ‚ Ï„Ï‰Î½ Î´Î¹Î±Ï†Î¿ÏÏÎ½
    """
    print(f"\n" + "="*80)
    print("ğŸ¤” Î Î™Î˜Î‘ÎÎ•Î£ Î‘Î™Î¤Î™Î•Î£ Î”Î™Î‘Î¦ÎŸÎ¡Î©Î:")
    print("="*80)
    
    print("""
1. ğŸ“ Î”Î™Î‘Î¦ÎŸÎ¡Î•Î¤Î™ÎšÎ— ÎœÎ•Î˜ÎŸÎ”ÎŸÎ£ ÎœÎ•Î¤Î¡Î—Î£Î—Î£:
   â€¢ Î¤Î¿ README Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¼ÎµÏ„ÏÎ¬ÎµÎ¹ ÏŒÎ»Î± Ï„Î± B- ÎºÎ±Î¹ I- tags
   â€¢ Î•Î¼ÎµÎ¯Ï‚ Î¼ÎµÏ„ÏÎ¬Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± B- tags (entities)
   
2. ğŸ”„ Î”Î™Î‘Î¦ÎŸÎ¡Î•Î¤Î™ÎšÎ— Î•ÎšÎ”ÎŸÎ£Î— DATASET:
   â€¢ Î¤Î¿ dataset Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î­Ï‡ÎµÎ¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Î¸ÎµÎ¯ Î¼ÎµÏ„Î¬ Ï„Î¿ README
   â€¢ Î Î¹Î¸Î±Î½Î® post-processing Î® ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
   
3. ğŸ“Š Î”Î™Î‘Î¦ÎŸÎ¡Î‘ Î£Î¤ÎŸ TOKENIZATION:
   â€¢ Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚ spaCy tokenizer
   â€¢ Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿Î¯ Ï„ÏÏŒÏ€Î¿Î¹ Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼Î¿Ï ÎµÎ¹Î´Î¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÏ‰Î½
   
4. ğŸ§¹ DATA CLEANING:
   â€¢ Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Î¼Î· Î­Î³ÎºÏ…ÏÏ‰Î½ Î® Ï€ÏÎ¿Î²Î»Î·Î¼Î±Ï„Î¹ÎºÏÎ½ annotations
   â€¢ Î”Î¹ÏŒÏÎ¸Ï‰ÏƒÎ· ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ ÏƒÏ„Î± Î±ÏÏ‡Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
   
5. ğŸ” Î”Î™Î‘Î¦ÎŸÎ¡Î•Î¤Î™ÎšÎŸÎ£ ÎŸÎ¡Î™Î£ÎœÎŸÎ£ ENTITY:
   â€¢ Î¤Î¿ README Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Ï„Î± multi-token entities
   """)

if __name__ == "__main__":
    compare_statistics()
    analyze_potential_causes()
    
    print(f"\nâœ… Î£Î¥ÎœÎ Î•Î¡Î‘Î£ÎœÎ‘:")
    print("Î¤Î± Î´Î¹ÎºÎ¬ Î¼Î±Ï‚ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ…Î½ÎµÏ€Î® Î¼Îµ Ï„Î· Î´Î¿Î¼Î® Ï„Î¿Ï… dataset,")
    print("Î±Î»Î»Î¬ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Ï†Î¿ÏÎ­Ï‚ Î¼Îµ Ï„Î± ÎµÏ€Î¯ÏƒÎ·Î¼Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Ï„Î¿Ï… README.")
    print("Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï†Ï…ÏƒÎ¹Î¿Î»Î¿Î³Î¹ÎºÏŒ ÎºÎ±Î¹ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î¿Ï†ÎµÎ¯Î»ÎµÏ„Î±Î¹ ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚")
    print("Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ Î¼Î­Ï„ÏÎ·ÏƒÎ·Ï‚ Î® ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… dataset.")
