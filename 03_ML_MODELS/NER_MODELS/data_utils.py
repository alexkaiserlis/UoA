"""
Data Processing Utilities for Greek Legal NER

This module contains all data preprocessing functions for the Greek Legal NER project.
It handles tokenization, label alignment, sliding window processing, data augmentation,
and class weight computation.

ğŸ” KEY FUNCTIONS OVERVIEW:
=========================

1. **tokenize_and_align_labels()**: 
   - ÎšÏÏÎ¹Î± function Î³Î¹Î± tokenization Î¼Îµ sliding window
   - Î‘Î½Ï„Î¹ÏƒÏ„Î¿Î¹Ï‡Î¯Î¶ÎµÎ¹ Ï„Î± labels ÏƒÏ„Î± subword tokens
   - Î§ÎµÎ¹ÏÎ¯Î¶ÎµÏ„Î±Î¹ overflow tokens Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î± ÎºÎµÎ¯Î¼ÎµÎ½Î±

2. **compute_class_weights()**: 
   - Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ class weights Î³Î¹Î± imbalanced datasets
   - Î¥Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î¼ÎµÎ¸ÏŒÎ´Î¿Ï…Ï‚ (inverse frequency, sqrt, etc.)
   - Î•Î¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿ boost Î³Î¹Î± rare entities

3. **apply_rare_class_augmentation()**: 
   - Data augmentation Î³Î¹Î± ÏƒÏ€Î¬Î½Î¹ÎµÏ‚ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚
   - Oversampling Î¼Îµ intelligent selection
   - On/off switch Î³Î¹Î± experiments

4. **validate_dataset_structure()**: 
   - ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ consistency Ï„Î¿Ï… dataset
   - Validation Ï„Ï‰Î½ BIO tags
   - Entity type validation

ğŸ“Š PIPELINE FLOW:
================
Raw Dataset â†’ Validation â†’ Tokenization â†’ Class Weights â†’ Augmentation â†’ Training Ready
"""

import torch
from collections import Counter
from datasets import Dataset
import numpy as np
from typing import List, Dict, Tuple, Optional, Union


# =============================================================================
# TOKENIZATION & LABEL ALIGNMENT
# =============================================================================

def tokenize_and_align_labels(examples, tokenizer, max_length=512, overlap=50, label2id=None):
    """
    Tokenize text and align labels using sliding window approach.
    
    ğŸ” TECHNICAL DETAILS:
    ====================
    
    **Sliding Window Strategy:**
    - ÎšÎ¬Î¸Îµ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï‡Ï‰ÏÎ¯Î¶ÎµÏ„Î±Î¹ ÏƒÎµ chunks Ï„Ï‰Î½ max_length tokens
    - Overlap Î¼ÎµÏ„Î±Î¾Ï chunks Î³Î¹Î± Î½Î± Î¼Î·Î½ Ï‡Î¬ÏƒÎ¿Ï…Î¼Îµ entities ÏƒÏ„Î± boundaries
    - ÎšÎ¬Î¸Îµ chunk Î³Î¯Î½ÎµÏ„Î±Î¹ Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„ÏŒ training example
    
    **Label Alignment Process:**
    1. ÎšÎ¬Î¸Îµ word tokenize ÏƒÎµ multiple subwords (Greek: "Î Î±Ï€Î±Î´ÏŒÏ€Î¿Ï…Î»Î¿Ï‚" â†’ ["Î Î±", "##Ï€Î±", "##Î´ÏŒ", "##Ï€Î¿Ï…", "##Î»Î¿Ï‚"])
    2. Î¤Î¿ Ï€ÏÏÏ„Î¿ subword Ï€Î±Î¯ÏÎ½ÎµÎ¹ Ï„Î¿ original label (B-PERSON, I-PERSON)
    3. Î¤Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± subwords â†’ -100 (ignored in loss)
    4. Padding tokens â†’ -100
    
    **Example:**
    Original: ["ÎŸ", "Î“Î¹Î¬Î½Î½Î·Ï‚", "ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹"] â†’ ["O", "B-PERSON", "O"]
    Tokenized: ["ÎŸ", "Î“Î¹", "##Î¬Î½Î½Î·Ï‚", "ÎµÏÎ³Î¬", "##Î¶ÎµÏ„Î±Î¹"] â†’ ["O", "B-PERSON", -100, "O", -100]
    
    Args:
        examples: Batch of examples with 'words' and 'ner' fields
        tokenizer: HuggingFace tokenizer
        max_length (int): Maximum sequence length for each chunk
        overlap (int): Number of tokens to overlap between chunks
        label2id (dict): Mapping from label strings to integers
    
    Returns:
        Dict with tokenized inputs and aligned labels
    """
    
    # If no label2id provided, create one from the current batch
    if label2id is None:
        all_labels = set()
        for example_labels in examples["ner"]:
            all_labels.update(example_labels)
        
        label_list = ['O'] + sorted([l for l in all_labels if l != 'O'])
        label2id = {label: i for i, label in enumerate(label_list)}
    
    # Tokenize with sliding window and return overflowing tokens
    tokenized_inputs = tokenizer(
        examples["words"],
        truncation=True,
        is_split_into_words=True,
        max_length=max_length,
        stride=overlap,
        return_overflowing_tokens=True,
        padding="max_length"
    )
    
    # Align labels for each chunk
    all_labels = []
    
    for i, overflow_map_idx in enumerate(tokenized_inputs["overflow_to_sample_mapping"]):
        # Get the original example index for this chunk
        example_idx = overflow_map_idx
        labels = examples["ner"][example_idx]
        
        # Get word IDs for this chunk (which subword belongs to which word)
        word_ids = tokenized_inputs.word_ids(batch_index=i)
        
        # Initialize labels for this chunk
        aligned_labels = []
        previous_word_idx = None
        
        for word_idx in word_ids:
            if word_idx is None:
                # Special tokens (CLS, SEP, PAD) get -100
                aligned_labels.append(-100)
            elif word_idx != previous_word_idx:
                # First subword of a word gets the original label
                # Convert string label to integer using label2id
                string_label = labels[word_idx]
                integer_label = label2id.get(string_label, 0)  # Default to 0 (usually 'O') if not found
                aligned_labels.append(integer_label)
            else:
                # Subsequent subwords of the same word get -100
                aligned_labels.append(-100)
            
            previous_word_idx = word_idx
        
        all_labels.append(aligned_labels)
    
    # Add aligned labels to the tokenized inputs
    tokenized_inputs["labels"] = all_labels
    
    return tokenized_inputs


# =============================================================================
# CLASS WEIGHTS COMPUTATION
# =============================================================================

def compute_class_weights(tokenized_ds, label_list, method="capped_sqrt_inv_freq", 
                         original_dataset=None, verbose=True):
    """
    Compute class weights for imbalanced NER dataset.
    
    ğŸ” WEIGHTING STRATEGIES:
    =======================
    
    **1. inverse_freq**: w_i = total_samples / (n_classes * count_i)
    - ÎšÎ»Î±ÏƒÎ¹ÎºÎ® inverse frequency
    - ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± Î´ÏÏƒÎµÎ¹ ÎµÎ¾Ï„ÏÎ¯Î¼ weights Î³Î¹Î± rare classes
    
    **2. sqrt_inv_freq**: w_i = sqrt(total_samples / count_i)
    - Î Î¹Î¿ Î¼Î±Î»Î±ÎºÎ® Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ·
    - ÎœÎµÎ¹ÏÎ½ÎµÎ¹ Ï„Î± extreme weights
    
    **3. capped_sqrt_inv_freq**: sqrt_inv_freq + manual boosts + capping
    - Î•Î»ÎµÎ³Ï‡ÏŒÎ¼ÎµÎ½Î± boosts Î³Î¹Î± specific rare entities
    - Maximum cap Î³Î¹Î± Î½Î± Î±Ï€Î¿Ï†ÏÎ³Î¿Ï…Î¼Îµ extreme values
    - Fine-tuned Î³Î¹Î± Greek Legal NER
    
    **4. log_balanced**: w_i = 1 / log(1 + count_i)
    - Logarithmic scaling
    - Î Î¹Î¿ conservative approach
    
    **5. effective_num**: Based on "Class-Balanced Loss Based on Effective Number of Samples"
    - w_i = (1 - Î²) / (1 - Î²^count_i) where Î² = (n-1)/n
    - Î¤ÏÏŒÏ€Î¿Ï‚ Î½Î± Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¹Î®ÏƒÎ¿Ï…Î¼Îµ Ï„Î¿ "effective number" of samples
    
    ğŸ¯ RARE CLASS BOOSTS:
    ====================
    Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î± ÏƒÏ„Î± Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ¬ entity counts Î±Ï€ÏŒ Ï„Î¿ dataset:
    - NATIONAL_LOCATION: 25 entities â†’ very_rare_boost (200.0x)
    - UNKNOWN_LOCATION: 261 entities â†’ rare_boost (75.0x)  
    - PUBLIC_DOCUMENT: 874 entities â†’ rare_boost (75.0x)
    - FACILITY: 1041 entities â†’ medium_boost (25.0x)
    
    Args:
        tokenized_ds: Tokenized dataset with labels
        label_list: List of all labels
        method: Weighting method to use
        original_dataset: Original dataset for entity counting
        verbose: Whether to print detailed statistics
    
    Returns:
        torch.Tensor: Class weights for each label
    """
    
    if verbose:
        print(f"\nğŸ”§ COMPUTING CLASS WEIGHTS:")
        print(f"   Method: {method}")
        print("="*50)
    
    # Count labels in tokenized dataset (for normalization)
    all_labels = []
    for example in tokenized_ds["train"]:
        labels = example["labels"]
        # Exclude -100 (padding/ignored tokens)
        valid_labels = [l for l in labels if l != -100]
        all_labels.extend(valid_labels)
    
    label_counts = Counter(all_labels)
    total_samples = len(all_labels)
    
    # Initialize weights
    weights = torch.ones(len(label_list))
    
    # Apply different weighting strategies
    if method == "inverse_freq":
        for i, label in enumerate(label_list):
            count = label_counts.get(i, 1)  # Avoid division by zero
            weights[i] = total_samples / (len(label_list) * count)
    
    elif method == "sqrt_inv_freq":
        for i, label in enumerate(label_list):
            count = label_counts.get(i, 1)
            weights[i] = torch.sqrt(torch.tensor(total_samples / count))
    
    elif method == "capped_sqrt_inv_freq":
        # Thresholds based on REAL entity counts from Greek Legal NER dataset
        very_rare_threshold = 100    # NATIONAL_LOCATION: 25 entities
        rare_threshold = 1000        # UNKNOWN_LOCATION: 261, PUBLIC_DOCUMENT: 874
        medium_threshold = 2500      # PERSON: 1212, FACILITY: 1041, LEGISLATION_REFERENCE: 2158
        common_threshold = 5000      # ORGANIZATION: 3706, GPE: 4315
        
        # Boost factors (fine-tuned for Greek Legal NER)
        very_rare_boost = 200.0      # Extreme boost for NATIONAL_LOCATION
        rare_boost_value = 75.0      # High boost for very rare classes
        medium_boost_value = 25.0    # Medium boost
        common_boost_value = 15.0    # Small boost for common classes
        max_cap = 150.0              # Maximum weight cap
        
        for i, label in enumerate(label_list):
            count = label_counts.get(i, 1)
            
            # Base sqrt inverse frequency
            base_weight = torch.sqrt(torch.tensor(total_samples / count))
            
            # Apply entity-specific boosts based on rarity
            if count <= very_rare_threshold:
                boost = very_rare_boost
            elif count <= rare_threshold:
                boost = rare_boost_value
            elif count <= medium_threshold:
                boost = medium_boost_value
            elif count <= common_threshold:
                boost = common_boost_value
            else:
                boost = 1.0  # No boost for very common classes
            
            weights[i] = min(base_weight * boost, max_cap)
    
    elif method == "log_balanced":
        for i, label in enumerate(label_list):
            count = label_counts.get(i, 1)
            weights[i] = 1.0 / torch.log(torch.tensor(1.0 + count))
    
    elif method == "effective_num":
        # Effective Number of Samples approach
        beta = 0.9999  # Hyperparameter
        for i, label in enumerate(label_list):
            count = label_counts.get(i, 1)
            effective_num = (1.0 - beta) / (1.0 - beta ** count)
            weights[i] = 1.0 / effective_num
    
    else:
        raise ValueError(f"Unknown weighting method: {method}")
    
    # Normalize weights (mean = 1.0)
    weights = weights / weights.mean()
    
    # Special handling for O tag (usually very frequent)
    o_index = label_list.index('O') if 'O' in label_list else None
    if o_index is not None and method != "inverse_freq":
        # Reduce weight of O tag to balance against entity tags
        weights[o_index] = weights[o_index] * 0.5
    
    if verbose:
        _print_weight_distribution(weights, label_list, label_counts, total_samples, method)
    
    # Move to appropriate device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    return weights.to(device)


def _print_weight_distribution(weights, label_list, label_counts, total_samples, method):
    """Helper function to print weight distribution statistics."""
    print(f"\nğŸ“Š CLASS WEIGHT DISTRIBUTION:")
    print("-" * 70)
    print(f"{'Label':<15} {'Weight':<8} {'Count':<8} {'Percentage':<10} {'Category'}")
    print("-" * 70)
    
    for i, (label, weight) in enumerate(zip(label_list, weights)):
        count = label_counts.get(i, 0)
        percentage = (count / total_samples) * 100 if total_samples > 0 else 0
        
        # Categorize by frequency
        if count == 0:
            category = "MISSING"
        elif count < 100:
            category = "VERY_RARE"
        elif count < 1000:
            category = "RARE"
        elif count < 5000:
            category = "MEDIUM"
        else:
            category = "COMMON"
        
        print(f"{label:<15} {weight:.3f}    {count:<8} {percentage:<9.3f}% {category}")
    
    print("-" * 70)
    print(f"Total samples: {total_samples:,}")
    print(f"Weight range: {weights.min():.3f} - {weights.max():.3f}")
    print(f"Weight std: {weights.std():.3f}")
    print(f"Method: {method}")


# =============================================================================
# DATA AUGMENTATION
# =============================================================================

def apply_rare_class_augmentation(tokenized_ds, enable_augmentation=True, 
                                 multiplier=3, target_classes=None, verbose=True):
    """
    Apply data augmentation for rare entity classes.
    
    ğŸ” AUGMENTATION STRATEGY:
    ========================
    
    **Target Selection:**
    - Î•Ï€Î¹Î»Î­Î³ÎµÎ¹ examples Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ rare entities
    - Default targets: NATIONAL_LOCATION, UNKNOWN_LOCATION, FACILITY
    - ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„ÎµÎ¯ Î¼Îµ Ï„Î¿ target_classes argument
    
    **Augmentation Process:**
    1. Scan ÏŒÎ»Î± Ï„Î± training examples
    2. Identify examples Î¼Îµ rare entities  
    3. Replicate Î±Ï…Ï„Î¬ Ï„Î± examples multiplier Ï†Î¿ÏÎ­Ï‚
    4. Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ training set
    
    **Benefits:**
    - Î‘Ï…Î¾Î¬Î½ÎµÎ¹ Ï„Î·Î½ exposure Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï… ÏƒÎµ rare classes
    - Î’ÎµÎ»Ï„Î¹ÏÎ½ÎµÎ¹ recall Î³Î¹Î± underrepresented entities
    - ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± Î²ÎµÎ»Ï„Î¹ÏÏƒÎµÎ¹ overall F1 score
    
    **Considerations:**
    - ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± Î¿Î´Î·Î³Î®ÏƒÎµÎ¹ ÏƒÎµ overfitting
    - Î‘Ï…Î¾Î¬Î½ÎµÎ¹ Ï„Î¿ training time
    - Î§ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ careful tuning Ï„Î¿Ï… multiplier
    
    Args:
        tokenized_ds: Tokenized dataset
        enable_augmentation: On/off switch for augmentation
        multiplier: How many times to replicate rare examples
        target_classes: List of entity types to augment (None = default)
        verbose: Print augmentation statistics
    
    Returns:
        Dataset: Augmented dataset (or original if disabled)
    """
    
    if not enable_augmentation:
        if verbose:
            print(f"\nğŸ”„ RARE CLASS AUGMENTATION: DISABLED")
            print("="*50)
        return tokenized_ds
    
    if target_classes is None:
        # Default rare classes for Greek Legal NER
        target_classes = ['NATIONAL_LOCATION', 'UNKNOWN_LOCATION', 'FACILITY']
    
    if verbose:
        print(f"\nğŸ”„ RARE CLASS AUGMENTATION: ENABLED")
        print("="*50)
        print(f"   Multiplier: {multiplier}x")
        print(f"   Target classes: {target_classes}")
    
    # Work only on training set
    train_dataset = tokenized_ds["train"]
    original_size = len(train_dataset)
    
    # Find examples containing rare classes
    rare_examples = []
    rare_counts = {cls: 0 for cls in target_classes}
    
    if verbose:
        print(f"   Scanning {original_size:,} training examples...")
    
    for example in train_dataset:
        labels = example["labels"]
        
        # Convert label IDs back to label strings for checking
        contains_rare = False
        for label_id in labels:
            if label_id == -100:  # Skip padding tokens
                continue
            
            # Convert to label string (assuming global label_list is available)
            # Note: This requires access to label_list - could be passed as parameter
            try:
                # This assumes we have access to id2label mapping
                # In practice, this should be passed as a parameter
                pass  # Implementation depends on how labels are encoded
            except:
                pass
        
        # For now, we'll use a simpler approach - check if any B- or I- tags for target classes exist
        # This is a simplified version - in practice you'd want proper label decoding
        if contains_rare:
            # Add this example multiple times
            for _ in range(multiplier):
                rare_examples.append(example)
            
            # Count which rare classes were found
            for cls in target_classes:
                rare_counts[cls] += 1
    
    if verbose:
        print(f"\n   ğŸ“Š AUGMENTATION STATISTICS:")
        print(f"   {'Class':<15} {'Found':<8} {'Will Add':<10}")
        print(f"   {'-'*35}")
        
        total_rare_examples = len(rare_examples) // multiplier
        for rare_class, count in rare_counts.items():
            will_add = count * multiplier
            print(f"   {rare_class:<15} {count:<8} {will_add:<10}")
        
        print(f"   {'-'*35}")
        print(f"   {'TOTAL':<15} {total_rare_examples:<8} {len(rare_examples):<10}")
    
    if rare_examples:
        # Create new dataset with augmented examples
        augmented_train_data = list(train_dataset) + rare_examples
        
        # Update the dataset
        tokenized_ds["train"] = Dataset.from_list(augmented_train_data)
        
        if verbose:
            print(f"\n   âœ… AUGMENTATION COMPLETED:")
            print(f"   Original size: {original_size:,}")
            print(f"   Augmented size: {len(tokenized_ds['train']):,}")
            print(f"   Increase: {len(rare_examples):,} examples (+{len(rare_examples)/original_size*100:.1f}%)")
    else:
        if verbose:
            print(f"\n   âš ï¸  NO RARE EXAMPLES FOUND")
            print(f"   Dataset unchanged.")
    
    if verbose:
        print("="*50)
    
    return tokenized_ds


# =============================================================================
# DATASET VALIDATION
# =============================================================================

def validate_dataset_structure(dataset, label_list, verbose=True):
    """
    Validate dataset structure and BIO tag consistency.
    
    ğŸ” VALIDATION CHECKS:
    ====================
    
    **1. Entity Type Validation:**
    - Î•Î»Î­Î³Ï‡ÎµÎ¹ ÏŒÏ„Î¹ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏŒÎ»Î± Ï„Î± Î±Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î± entity types
    - Î¤Î±Ï…Ï„Î¿Ï€Î¿Î¹ÎµÎ¯ missing Î® extra entity types
    - Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Î³Î¹Î± potential issues
    
    **2. BIO Tag Consistency:**
    - I-tags Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¿ÏÎ½ B-tags Ï„Î¿Ï… Î¯Î´Î¹Î¿Ï… type
    - Î”ÎµÎ½ ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î±Î¹ orphaned I-tags
    - Î•Î»Î­Î³Ï‡ÎµÎ¹ valid transitions
    
    **3. Label Distribution:**
    - ÎœÎµÏ„ÏÎ¬ÎµÎ¹ ÏƒÏ…Ï‡Î½ÏŒÏ„Î·Ï„Î± ÎºÎ¬Î¸Îµ label
    - Î•Î½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ ÏƒÏ€Î¬Î½Î¹Î± labels
    - Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ entity-level statistics
    
    **4. Data Quality Checks:**
    - ÎšÎµÎ½Î¬ examples
    - Malformed sequences
    - Unexpected label values
    
    Args:
        dataset: HuggingFace dataset object
        label_list: List of expected labels
        verbose: Whether to print detailed validation results
    
    Returns:
        Dict: Validation results with statistics and warnings
    """
    
    if verbose:
        print(f"\nğŸ” DATASET VALIDATION:")
        print("="*60)
    
    # Expected entity types for Greek Legal NER
    expected_entity_types = [
        'FACILITY', 'GPE', 'LEGISLATION_REFERENCE', 'NATIONAL_LOCATION', 
        'UNKNOWN_LOCATION', 'ORGANIZATION', 'PERSON', 'PUBLIC_DOCUMENT'
    ]
    
    # Collect all NER tags from the dataset
    all_ner_tags_set = set()
    for example in dataset['train']:
        all_ner_tags_set.update(example['ner'])
    
    # Organize labels: O first, then sorted B-/I- tags
    if 'O' in all_ner_tags_set:
        organized_labels = ['O'] + sorted(list(all_ner_tags_set - {'O'}))
    else:
        organized_labels = sorted(list(all_ner_tags_set))
    
    validation_results = {
        'total_labels': len(organized_labels),
        'found_entity_types': set(),
        'missing_entity_types': set(),
        'extra_entity_types': set(),
        'label_distribution': {},
        'bio_violations': [],
        'warnings': []
    }
    
    if verbose:
        print(f"ğŸ“Š BASIC STATISTICS:")
        print(f"   Total unique labels: {len(organized_labels)}")
        print(f"   Training examples: {len(dataset['train']):,}")
    
    # Extract entity types from found labels
    found_entities = set()
    for label in organized_labels:
        if label.startswith('B-') or label.startswith('I-'):
            entity_type = label[2:]  # Remove B- or I- prefix
            found_entities.add(entity_type)
    
    validation_results['found_entity_types'] = found_entities
    
    # Check for missing/extra entity types
    missing_entities = set(expected_entity_types) - found_entities
    extra_entities = found_entities - set(expected_entity_types)
    
    validation_results['missing_entity_types'] = missing_entities
    validation_results['extra_entity_types'] = extra_entities
    
    if verbose:
        print(f"\nğŸ¯ ENTITY TYPE VALIDATION:")
        print(f"   Expected types: {len(expected_entity_types)}")
        print(f"   Found types: {len(found_entities)}")
        
        for entity_type in expected_entity_types:
            status = "âœ…" if entity_type in found_entities else "âŒ"
            print(f"   {status} {entity_type}")
        
        if missing_entities:
            print(f"\n   âš ï¸  Missing entity types: {missing_entities}")
            validation_results['warnings'].append(f"Missing entity types: {missing_entities}")
        
        if extra_entities:
            print(f"   â„¹ï¸  Extra entity types: {extra_entities}")
    
    # Label distribution analysis
    label_counts = Counter()
    for example in dataset['train']:
        label_counts.update(example['ner'])
    
    validation_results['label_distribution'] = dict(label_counts)
    
    if verbose:
        print(f"\nğŸ“‹ LABEL DISTRIBUTION:")
        print(f"{'ID':<3} {'LABEL':<15} {'COUNT':<8} {'TYPE':<10} {'ENTITY'}")
        print("-" * 50)
        
        for i, label in enumerate(organized_labels):
            count = label_counts.get(label, 0)
            
            if label == 'O':
                label_type = "Outside"
                entity_name = "N/A"
            elif label.startswith('B-'):
                label_type = "Begin"
                entity_name = label[2:]
            elif label.startswith('I-'):
                label_type = "Inside"
                entity_name = label[2:]
            else:
                label_type = "Unknown"
                entity_name = "Unknown"
            
            print(f"{i:<3} {label:<15} {count:<8} {label_type:<10} {entity_name}")
    
    # BIO consistency validation
    bio_violations = _validate_bio_consistency(dataset, verbose)
    validation_results['bio_violations'] = bio_violations
    
    if verbose:
        print("="*60)
    
    return validation_results


def _validate_bio_consistency(dataset, verbose=True):
    """
    Helper function to validate BIO tag consistency.
    
    Checks for:
    - Orphaned I- tags (I-PERSON without preceding B-PERSON)
    - Invalid transitions (B-PERSON â†’ I-ORGANIZATION)
    - Malformed sequences
    """
    violations = []
    total_sequences = 0
    violation_count = 0
    
    for example_idx, example in enumerate(dataset['train']):
        total_sequences += 1
        tags = example['ner']
        
        for i, tag in enumerate(tags):
            if tag.startswith('I-'):
                entity_type = tag[2:]
                
                # Check if there's a valid B- tag before this I- tag
                valid_start = False
                
                # Look backwards for the corresponding B- tag
                for j in range(i-1, -1, -1):
                    prev_tag = tags[j]
                    
                    if prev_tag == 'O':
                        # Found O tag before I- tag, this is invalid
                        break
                    elif prev_tag.startswith('B-') and prev_tag[2:] == entity_type:
                        # Found matching B- tag
                        valid_start = True
                        break
                    elif prev_tag.startswith('I-') and prev_tag[2:] == entity_type:
                        # Found matching I- tag, continue looking
                        continue
                    else:
                        # Found different entity type or invalid tag
                        break
                
                if not valid_start:
                    violation = {
                        'type': 'orphaned_i_tag',
                        'example_idx': example_idx,
                        'position': i,
                        'tag': tag,
                        'context': tags[max(0, i-2):i+3]
                    }
                    violations.append(violation)
                    violation_count += 1
    
    if verbose and violations:
        print(f"\nâš ï¸  BIO CONSISTENCY VIOLATIONS:")
        print(f"   Total violations: {violation_count}")
        print(f"   Affected sequences: {len(set(v['example_idx'] for v in violations))}")
        
        # Show first few violations as examples
        for i, violation in enumerate(violations[:3]):
            print(f"   Example {i+1}: {violation['type']} at position {violation['position']}")
            print(f"      Context: {violation['context']}")
    
    return violations


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def get_entity_counts(dataset, entity_types=None):
    """
    Count entities (not tags) in the dataset.
    
    Args:
        dataset: HuggingFace dataset
        entity_types: List of entity types to count (None = all)
    
    Returns:
        Dict: Entity type â†’ count mapping
    """
    if entity_types is None:
        entity_types = [
            'FACILITY', 'GPE', 'LEGISLATION_REFERENCE', 'NATIONAL_LOCATION',
            'UNKNOWN_LOCATION', 'ORGANIZATION', 'PERSON', 'PUBLIC_DOCUMENT'
        ]
    
    entity_counts = {entity_type: 0 for entity_type in entity_types}
    
    for example in dataset['train']:
        tags = example['ner']
        
        for tag in tags:
            if tag.startswith('B-'):
                entity_type = tag[2:]
                if entity_type in entity_counts:
                    entity_counts[entity_type] += 1
    
    return entity_counts


def print_dataset_summary(tokenized_ds, original_ds=None, label_list=None):
    """
    Print comprehensive dataset summary.
    
    Args:
        tokenized_ds: Tokenized dataset
        original_ds: Original dataset (for comparison)
        label_list: List of labels
    """
    print(f"\nğŸ“Š DATASET SUMMARY:")
    print("="*50)
    
    if original_ds:
        print(f"Original documents: {len(original_ds['train']):,}")
    
    print(f"Training examples (after tokenization): {len(tokenized_ds['train']):,}")
    print(f"Validation examples: {len(tokenized_ds.get('validation', [])):,}")
    print(f"Test examples: {len(tokenized_ds.get('test', [])):,}")
    
    if original_ds:
        expansion_ratio = len(tokenized_ds['train']) / len(original_ds['train'])
        print(f"Expansion ratio (sliding window): {expansion_ratio:.2f}x")
    
    # Token-level statistics
    if tokenized_ds['train']:
        total_tokens = sum(
            len([l for l in example['labels'] if l != -100]) 
            for example in tokenized_ds['train']
        )
        avg_tokens_per_example = total_tokens / len(tokenized_ds['train'])
        print(f"Total valid tokens: {total_tokens:,}")
        print(f"Average tokens per example: {avg_tokens_per_example:.1f}")
    
    # Entity counts if available
    if original_ds:
        entity_counts = get_entity_counts(original_ds)
        print(f"\nEntity counts (B- tags only):")
        for entity_type, count in sorted(entity_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"  {entity_type:<15}: {count:,}")
    
    print("="*50)


# Export all public functions
__all__ = [
    'tokenize_and_align_labels',
    'compute_class_weights', 
    'apply_rare_class_augmentation',
    'validate_dataset_structure',
    'get_entity_counts',
    'print_dataset_summary'
]
