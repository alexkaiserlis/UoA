#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Eurovoc Concept Classifier using TF-IDF on Generated Summaries

This system classifies input text to the most relevant Eurovoc concepts
using TF-IDF similarity on our generated concept summaries.

Features:
- TF-IDF vectorization with configurable parameters
- Top-K concept retrieval with confidence scores
- Evaluation metrics (Recall@K, ZSR@K)
- Support for unseen label evaluation
- Comprehensive performance analytics
"""

import os
import json
import numpy as np
import pandas as pd
from datetime import datetime
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass
from collections import defaultdict
import re

# TF-IDF ÎºÎ±Î¹ ML imports
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import normalize

# PDF processing imports
try:
    import PyPDF2
    import fitz  # PyMuPDF
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# Greek stopwords (Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± ÎµÏ€ÎµÎºÏ„ÎµÎ¯Î½Î¿Ï…Î¼Îµ)
GREEK_STOPWORDS = {
    'ÎºÎ±Î¹', 'Î®', 'Ï„Ï‰Î½', 'Ï„Î·Ï‚', 'Ï„Î¿Ï…', 'Ï„Î¿', 'Ï„Î±', 'ÏƒÏ„Î¿', 'ÏƒÏ„Î·', 'ÏƒÏ„Î·Î½', 'ÏƒÏ„Î±', 
    'Î³Î¹Î±', 'Î¼Îµ', 'Î±Ï€ÏŒ', 'Ï€ÏÎ¿Ï‚', 'ÎºÎ±Ï„Î¬', 'Î¼ÎµÏ„Î¬', 'Ï‡Ï‰ÏÎ¯Ï‚', 'Ï€Î±ÏÎ¬', 'ÎµÎ¹Ï‚', 'Ï‰Ï‚',
    'ÎµÎ¯Î½Î±Î¹', 'Î®Ï„Î±Î½', 'Î¸Î±', 'Î½Î±', 'ÏŒÏ„Î¹', 'Î±Î½', 'ÏŒÏ„Î±Î½', 'ÏŒÏ€Î¿Ï…', 'ÏŒÏ€Ï‰Ï‚', 'Î±Î»Î»Î¬',
    'Î¼Î¹Î±', 'Î­Î½Î±', 'Î¼Î±Ï‚', 'ÏƒÎ±Ï‚', 'Ï„Î¿Ï…Ï‚', 'Ï„Î¹Ï‚', 'Ï„Î¿Î½', 'Ï„Î·Î½', 'ÏŒÎ»Î±', 'ÏŒÎ»ÎµÏ‚',
    'Ï€Ï‰Ï‚', 'Ï€Î¿Ï', 'Ï„Î¹', 'Ï€Î¿Î¹Î±', 'Ï€Î¿Î¹Î¿', 'Ï€Î¿Î¹ÎµÏ‚', 'Ï€Î¿Î¹Î¿Ï…Ï‚', 'Ï€Î¿Î¹Ï‰Î½'
}

ENGLISH_STOPWORDS = {
    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 
    'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 
    'will', 'with', 'or', 'but', 'not', 'this', 'these', 'they', 'them',
    'have', 'had', 'can', 'could', 'should', 'would', 'may', 'might',
    'all', 'any', 'each', 'every', 'some', 'such', 'no', 'nor', 'too',
    'very', 'just', 'now', 'only', 'also', 'into', 'over', 'after',
    'other', 'which', 'their', 'what', 'there', 'when', 'where', 'who',
    'how', 'up', 'out', 'if', 'about', 'were', 'been', 'being', 'do',
    'does', 'did', 'doing', 'than', 'through', 'during', 'before'
}

ALL_STOPWORDS = GREEK_STOPWORDS.union(ENGLISH_STOPWORDS)

@dataclass
class ClassificationResult:
    """Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± classification Î³Î¹Î± Î­Î½Î± ÎºÎµÎ¯Î¼ÎµÎ½Î¿."""
    query_text: str
    predicted_concepts: List[Tuple[str, str, float]]  # (concept_id, title, score)
    true_concepts: Optional[Set[str]] = None
    processing_time: float = 0.0
    query_length: int = 0

@dataclass
class EvaluationMetrics:
    """ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚ Î³Î¹Î± Top-K evaluation."""
    k: int
    recall_at_k: float
    zsr_at_k: float  # Zero-Shot Recall
    precision_at_k: float = 0.0
    f1_at_k: float = 0.0

class EurovocClassifier:
    """
    Eurovoc Concept Classifier using TF-IDF on concept summaries.
    """
    
    def __init__(self, summaries_dir: str, config: Optional[Dict] = None):
        """
        Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· classifier.
        
        Args:
            summaries_dir: ÎšÎ±Ï„Î¬Î»Î¿Î³Î¿Ï‚ Î¼Îµ Ï„Î± summary JSON Î±ÏÏ‡ÎµÎ¯Î±
            config: Î Î±ÏÎ±Î¼ÎµÏ„ÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· TF-IDF ÎºÎ±Î¹ classifier
        """
        self.summaries_dir = os.path.abspath(summaries_dir)
        self.config = config or self._default_config()
        
        # Data containers
        self.concept_summaries = {}  # concept_id -> summary_text
        self.concept_metadata = {}   # concept_id -> full_metadata
        self.vectorizer = None
        self.tfidf_matrix = None
        self.concept_ids = []        # Ordered list of concept IDs
        
        # Performance tracking
        self.classification_stats = {
            'total_queries': 0,
            'total_concepts_loaded': 0,
            'avg_processing_time': 0.0,
            'last_update': None
        }
    
    def _default_config(self) -> Dict:
        """Î ÏÎ¿ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Ï€Î±ÏÎ±Î¼ÎµÏ„ÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚."""
        return {
            'tfidf_params': {
                'lowercase': True,
                'ngram_range': (1, 1),  # Unigrams to trigrams
                'stop_words': list(ALL_STOPWORDS),
                'max_features': 50000,
                'min_df': 2,            # Ignore terms in less than 2 documents
                'max_df': 0.95,         # Ignore terms in more than 95% of documents
                'sublinear_tf': True,   # Use log-scaled term frequencies
                'norm': 'l2'            # L2 normalization
            },
            'classification_params': {
                'similarity_metric': 'cosine',
                'top_k_default': 10,
                'min_score_threshold': 0.01
            },
            'evaluation_params': {
                'top_k_values': [1, 3, 5, 10, 50],
                'include_zsr': True,    # Zero-Shot Recall
                'unseen_label_ratio': 0.3
            }
        }
    
    def load_summaries(self, verbose: bool = True) -> bool:
        """
        Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ concept summaries Î±Ï€ÏŒ Ï„Î¿Î½ ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿.
        
        Returns:
            bool: True Î±Î½ Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Î®Ï„Î±Î½ ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚
        """
        if verbose:
            print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· summaries Î±Ï€ÏŒ: {self.summaries_dir}")
        
        if not os.path.exists(self.summaries_dir):
            print(f"âŒ ÎšÎ±Ï„Î¬Î»Î¿Î³Î¿Ï‚ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹: {self.summaries_dir}")
            return False
        
        summary_files = [f for f in os.listdir(self.summaries_dir) 
                        if f.endswith('_summary.json')]
        
        if not summary_files:
            print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ summary Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿ {self.summaries_dir}")
            return False
        
        loaded = 0
        failed = 0
        
        for filename in summary_files:
            try:
                # Extract concept ID Î±Ï€ÏŒ Ï„Î¿ filename
                # Format: concept_XXXX_summary.json
                concept_id = filename.replace('concept_', '').replace('_summary.json', '')
                
                filepath = os.path.join(self.summaries_dir, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Î•Î¾Î±Î³Ï‰Î³Î® summary text
                summary_text = data.get('summary', '')
                if not summary_text:
                    print(f"âš ï¸  ÎšÎµÎ½Î® Ï€ÎµÏÎ¯Î»Î·ÏˆÎ· Î³Î¹Î± concept {concept_id}")
                    continue
                
                self.concept_summaries[concept_id] = summary_text
                self.concept_metadata[concept_id] = data
                loaded += 1
                
            except Exception as e:
                print(f"âŒ Î£Ï†Î¬Î»Î¼Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ {filename}: {e}")
                failed += 1
                continue
        
        if verbose:
            print(f"âœ… Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {loaded:,} concept summaries")
            if failed > 0:
                print(f"âš ï¸  {failed} Î±Ï€Î¿Ï„Ï…Ï‡Î¯ÎµÏ‚ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚")
        
        self.classification_stats['total_concepts_loaded'] = loaded
        self.classification_stats['last_update'] = datetime.now().isoformat()
        
        return loaded > 0
    
    def build_tfidf_index(self, verbose: bool = True) -> bool:
        """
        Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± TF-IDF index Î±Ï€ÏŒ Ï„Î± summaries.
        
        Returns:
            bool: True Î±Î½ Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î®Ï„Î±Î½ ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚
        """
        if not self.concept_summaries:
            print("âŒ Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ summaries. ÎšÎ±Î»Î­ÏƒÏ„Îµ Ï€ÏÏÏ„Î± load_summaries()")
            return False
        
        if verbose:
            print(f"ğŸ”§ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± TF-IDF index Î¼Îµ {len(self.concept_summaries):,} concepts...")
        
        # Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        self.concept_ids = list(self.concept_summaries.keys())
        summary_texts = [self.concept_summaries[cid] for cid in self.concept_ids]
        
        # TF-IDF vectorization
        try:
            self.vectorizer = TfidfVectorizer(**self.config['tfidf_params'])
            self.tfidf_matrix = self.vectorizer.fit_transform(summary_texts)
            
            if verbose:
                print(f"âœ… TF-IDF index Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ:")
                print(f"   â€¢ Vocabulary size: {len(self.vectorizer.vocabulary_):,}")
                print(f"   â€¢ Matrix shape: {self.tfidf_matrix.shape}")
                print(f"   â€¢ Sparsity: {(1 - self.tfidf_matrix.nnz / np.prod(self.tfidf_matrix.shape)):.3f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Î£Ï†Î¬Î»Î¼Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ TF-IDF index: {e}")
            return False
    
    def classify_text(self, query_text: str, top_k: int = 10, 
                     return_scores: bool = True) -> ClassificationResult:
        """
        Classification ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… ÏƒÎµ Eurovoc concepts.
        
        Args:
            query_text: Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï€ÏÎ¿Ï‚ classification
            top_k: Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ top concepts Î½Î± ÎµÏ€Î¹ÏƒÏ„ÏÎ±Ï†Î¿ÏÎ½
            return_scores: Î‘Î½ Î½Î± ÏƒÏ…Î¼Ï€ÎµÏÎ¹Î»Î·Ï†Î¸Î¿ÏÎ½ Ï„Î± scores
            
        Returns:
            ClassificationResult: Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± classification
        """
        start_time = datetime.now()
        
        if not self.vectorizer or self.tfidf_matrix is None:
            raise ValueError("TF-IDF index Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î·Î¸ÎµÎ¯. ÎšÎ±Î»Î­ÏƒÏ„Îµ build_tfidf_index()")
        
        # Vectorization Ï„Î¿Ï… query
        query_vector = self.vectorizer.transform([query_text])
        
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ similarity Î¼Îµ ÏŒÎ»Î± Ï„Î± concepts
        similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()
        
        # Top-K concepts
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± results
        predicted_concepts = []
        min_threshold = self.config['classification_params']['min_score_threshold']
        
        for idx in top_indices:
            concept_id = self.concept_ids[idx]
            score = similarities[idx]
            
            if score < min_threshold:
                break
                
            # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿Î½ Ï„Î¯Ï„Î»Î¿ Î±Ï€ÏŒ metadata
            title = self.concept_metadata[concept_id].get('concept_data', {}).get('title', 'Unknown')
            predicted_concepts.append((concept_id, title, score))
        
        # Timing
        processing_time = (datetime.now() - start_time).total_seconds()
        
        result = ClassificationResult(
            query_text=query_text,
            predicted_concepts=predicted_concepts,
            processing_time=processing_time,
            query_length=len(query_text.split())
        )
        
        # Update stats
        self.classification_stats['total_queries'] += 1
        self.classification_stats['avg_processing_time'] = (
            (self.classification_stats['avg_processing_time'] * (self.classification_stats['total_queries'] - 1) + 
             processing_time) / self.classification_stats['total_queries']
        )
        
        return result
    
    def evaluate_on_dataset(self, test_data: List[Dict], 
                           top_k_values: Optional[List[int]] = None,
                           verbose: bool = True) -> Dict[int, EvaluationMetrics]:
        """
        Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ ÏƒÎµ test dataset.
        
        Args:
            test_data: List of {'text': str, 'concepts': List[str]}
            top_k_values: List of K values for evaluation
            verbose: Print progress
            
        Returns:
            Dict mapping K -> EvaluationMetrics
        """
        if top_k_values is None:
            top_k_values = self.config['evaluation_params']['top_k_values']
        
        if verbose:
            print(f"ğŸ“Š Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· ÏƒÎµ {len(test_data):,} test samples...")
        
        results = {}
        max_k = max(top_k_values)
        
        # Classification Î³Î¹Î± ÏŒÎ»Î± Ï„Î± test samples
        all_predictions = []
        all_true_labels = []
        
        for i, sample in enumerate(test_data):
            if verbose and (i + 1) % 100 == 0:
                print(f"   Progress: {i+1:,}/{len(test_data):,}")
            
            text = sample['text']
            true_concepts = set(sample['concepts'])
            
            # Classification
            result = self.classify_text(text, top_k=max_k)
            predicted_concepts = [pred[0] for pred in result.predicted_concepts]
            
            all_predictions.append(predicted_concepts)
            all_true_labels.append(true_concepts)
        
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ Î³Î¹Î± ÎºÎ¬Î¸Îµ K
        for k in top_k_values:
            recall_scores = []
            zsr_scores = []  # Zero-Shot Recall
            
            for predicted, true_set in zip(all_predictions, all_true_labels):
                predicted_k = predicted[:k]
                predicted_set = set(predicted_k)
                
                # Recall@K
                if len(true_set) > 0:
                    recall = len(predicted_set.intersection(true_set)) / len(true_set)
                    recall_scores.append(recall)
                
                # ZSR@K (Zero-Shot Recall)
                if len(predicted_set) > 0:
                    zsr = len(predicted_set.intersection(true_set)) / len(predicted_set)
                    zsr_scores.append(zsr)
            
            # ÎœÎ­ÏƒÎ¿Î¹ ÏŒÏÎ¿Î¹
            avg_recall = np.mean(recall_scores) if recall_scores else 0.0
            avg_zsr = np.mean(zsr_scores) if zsr_scores else 0.0
            
            results[k] = EvaluationMetrics(
                k=k,
                recall_at_k=avg_recall,
                zsr_at_k=avg_zsr
            )
        
        if verbose:
            print("âœ… Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
            self._print_evaluation_results(results)
        
        return results
    
    def _print_evaluation_results(self, results: Dict[int, EvaluationMetrics]):
        """Î•ÎºÏ„ÏÏ€Ï‰ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚."""
        print(f"\nğŸ“ˆ EVALUATION RESULTS:")
        print("=" * 50)
        
        for k in sorted(results.keys()):
            metrics = results[k]
            print(f"\nTop-{k} Evaluation")
            if k == 1:
                print("        with unseen labels")
            print(f"   ğŸ”¹ Recall@{k}: {metrics.recall_at_k:.4f}")
            print(f"   ğŸ”¹ ZSR@{k}:  {metrics.zsr_at_k:.4f}")
    
    def save_evaluation_report(self, results: Dict[int, EvaluationMetrics], 
                              output_file: str, test_info: Optional[Dict] = None):
        """Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ®Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚."""
        report = {
            'timestamp': datetime.now().isoformat(),
            'classifier_config': self.config,
            'classification_stats': self.classification_stats,
            'test_info': test_info or {},
            'evaluation_results': {
                str(k): {
                    'k': metrics.k,
                    'recall_at_k': metrics.recall_at_k,
                    'zsr_at_k': metrics.zsr_at_k,
                    'precision_at_k': metrics.precision_at_k,
                    'f1_at_k': metrics.f1_at_k
                }
                for k, metrics in results.items()
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ Evaluation report Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ: {output_file}")
    
    def get_system_info(self) -> Dict:
        """Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ ÎºÎ±Î¹ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬."""
        vocab_size = len(self.vectorizer.vocabulary_) if self.vectorizer else 0
        matrix_shape = self.tfidf_matrix.shape if self.tfidf_matrix is not None else (0, 0)
        
        return {
            'loaded_concepts': len(self.concept_summaries),
            'vocabulary_size': vocab_size,
            'tfidf_matrix_shape': matrix_shape,
            'classification_stats': self.classification_stats,
            'config': self.config
        }

def extract_pdf_text(pdf_path: str, max_chars: int = 50000) -> str:
    """
    Î•Î¾Î±Î³Ï‰Î³Î® ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… Î±Ï€ÏŒ PDF Î±ÏÏ‡ÎµÎ¯Î¿.
    
    Args:
        pdf_path: Î”Î¹Î±Î´ÏÎ¿Î¼Î® Ï€ÏÎ¿Ï‚ Ï„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿
        max_chars: ÎœÎ­Î³Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÏ‰Î½ Î½Î± ÎµÎ¾Î±Ï‡Î¸Î¿ÏÎ½
        
    Returns:
        str: Î•Î¾Î±Î³Î¼Î­Î½Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î±Ï€ÏŒ Ï„Î¿ PDF
    """
    if not os.path.exists(pdf_path):
        return ""
    
    text = ""
    
    # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î¼Îµ PyMuPDF (fitz) Ï€ÏÏÏ„Î± - ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î³Î¹Î± complex PDFs
    if PDF_AVAILABLE:
        try:
            import fitz
            doc = fitz.open(pdf_path)
            for page_num in range(min(10, len(doc))):  # Î ÏÏÏ„ÎµÏ‚ 10 ÏƒÎµÎ»Î¯Î´ÎµÏ‚
                page = doc.load_page(page_num)
                text += page.get_text()
                if len(text) > max_chars:
                    break
            doc.close()
            
            if text.strip():
                return text[:max_chars]
                
        except Exception as e:
            print(f"   âš ï¸  PyMuPDF failed Î³Î¹Î± {os.path.basename(pdf_path)}: {e}")
    
    # Fallback ÏƒÎµ PyPDF2
    if PDF_AVAILABLE:
        try:
            import PyPDF2
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page_num in range(min(10, len(pdf_reader.pages))):
                    page = pdf_reader.pages[page_num]
                    text += page.extract_text()
                    if len(text) > max_chars:
                        break
                        
            if text.strip():
                return text[:max_chars]
                
        except Exception as e:
            print(f"   âš ï¸  PyPDF2 failed Î³Î¹Î± {os.path.basename(pdf_path)}: {e}")
    
    # Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯Î¿ fallback - manual text extraction
    try:
        # Î‘Î½ Î´ÎµÎ½ Î­Ï‡Î¿Ï…Î¼Îµ PDF libraries, Ï€ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Î´Î¹Î±Î²Î¬ÏƒÎ¿Ï…Î¼Îµ Ï‰Ï‚ text
        with open(pdf_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read(max_chars)
        return text
    except:
        return ""

def load_test_pdfs(test_folder: str, max_files: int = 5) -> List[Dict]:
    """
    Î¦ÏŒÏÏ„Ï‰ÏƒÎ· PDF Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î±Ï€ÏŒ test folder Î³Î¹Î± classification testing.
    
    Args:
        test_folder: Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î¼Îµ PDF Î±ÏÏ‡ÎµÎ¯Î±
        max_files: ÎœÎ­Î³Î¹ÏƒÏ„Î¿Ï‚ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î½Î± Ï†Î¿ÏÏ„Ï‰Î¸Î¿ÏÎ½
        
    Returns:
        List of test samples Î¼Îµ format {'text': str, 'filename': str, 'concepts': List[str]}
    """
    if not PDF_AVAILABLE:
        print("âš ï¸  PDF libraries Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚!")
        print("   Î•Î³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÏ„Îµ Î¼Îµ: pip install PyPDF2 PyMuPDF")
        return []
    
    print(f"ğŸ“‚ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· PDF Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î±Ï€ÏŒ: {test_folder}")
    
    if not os.path.exists(test_folder):
        print(f"âŒ Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹: {test_folder}")
        return []
    
    # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ ÏŒÎ»Î± Ï„Î± PDF Î±ÏÏ‡ÎµÎ¯Î±
    pdf_files = [f for f in os.listdir(test_folder) if f.lower().endswith('.pdf')]
    
    if not pdf_files:
        print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ PDF Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿ {test_folder}")
        return []
    
    # Î ÎµÏÎ¹Î¿ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î±ÏÎ¹Î¸Î¼ÏŒ Î±ÏÏ‡ÎµÎ¯Ï‰Î½
    pdf_files = pdf_files[:max_files]
    
    print(f"ğŸ“„ Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(pdf_files)} PDF Î±ÏÏ‡ÎµÎ¯Î±")
    
    test_samples = []
    
    for i, filename in enumerate(pdf_files, 1):
        print(f"   {i}/{len(pdf_files)} Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±: {filename}...")
        
        pdf_path = os.path.join(test_folder, filename)
        
        # Î•Î¾Î±Î³Ï‰Î³Î® ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
        text = extract_pdf_text(pdf_path, max_chars=30000)  # ~30K chars Î³Î¹Î± ÎºÎ±Î»Î® Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
        
        if not text.strip():
            print(f"   âš ï¸  Î”ÎµÎ½ ÎµÎ¾Î®Ï‡Î¸Î· ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î±Ï€ÏŒ {filename}")
            continue
        
        # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
        text = re.sub(r'\s+', ' ', text)  # Normalize whitespace
        text = text.strip()
        
        if len(text) < 100:  # Î Î¿Î»Ï Î¼Î¹ÎºÏÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿
            print(f"   âš ï¸  Î Î¿Î»Ï Î¼Î¹ÎºÏÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î³Î¹Î± {filename}")
            continue
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± test sample
        sample = {
            'text': text,
            'filename': filename,
            'concepts': [],  # Î˜Î± Ï„Î± ÏƒÏ…Î¼Ï€Î»Î·ÏÏÏƒÎµÏ„Îµ Ï‡ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î± Î® Î±Ï€ÏŒ metadata
            'text_length': len(text.split()),
            'char_length': len(text)
        }
        
        test_samples.append(sample)
        print(f"   âœ… Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ: {len(text.split())} Î»Î­Î¾ÎµÎ¹Ï‚, {len(text)} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚")
    
    print(f"âœ… Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(test_samples)} PDF Î±ÏÏ‡ÎµÎ¯Î±")
    
    return test_samples

def main():
    """Demo ÎºÎ±Î¹ testing Ï„Î¿Ï… classifier Î¼Îµ PDF Î±ÏÏ‡ÎµÎ¯Î±."""
    print("ğŸ¯ EUROVOC CONCEPT CLASSIFIER - PDF TESTING")
    print("=" * 60)
    
    # Î Î±ÏÎ±Î¼ÎµÏ„ÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· paths
    current_dir = os.path.dirname(__file__)
    summaries_dir = os.path.join(current_dir, 'summaries')
    
    # Î¦Î¬ÎºÎµÎ»Î¿Ï‚ Î¼Îµ test PDF Î±ÏÏ‡ÎµÎ¯Î± (relative ÏƒÏ„Î¿ IR directory)
    parent_dir = os.path.dirname(current_dir)  # FINAL_VOCABULARY_PACKAGE
    test_pdfs_dir = os.path.join(parent_dir, 'TEST_LEGISLATIONS')
    
    print(f"ğŸ“ Summaries directory: {summaries_dir}")
    print(f"ğŸ“ Test PDFs directory: {test_pdfs_dir}")
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± classifier
    classifier = EurovocClassifier(summaries_dir)
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    print("\nğŸ”§ Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· classifier...")
    if not classifier.load_summaries():
        print("âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ summaries")
        print("   Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î­Ï‡ÎµÏ„Îµ Ï„ÏÎ­Î¾ÎµÎ¹ batch summary generation Ï€ÏÏÏ„Î±")
        return
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± TF-IDF index
    if not classifier.build_tfidf_index():
        print("âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ TF-IDF index")
        return
    
    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ PDF Î±ÏÏ‡ÎµÎ¯Î±
    if not os.path.exists(test_pdfs_dir):
        print(f"\nâš ï¸  TEST_LEGISLATIONS Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹: {test_pdfs_dir}")
        print("   Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Ï default test texts...")
        
        # Fallback ÏƒÎµ default test texts
        test_texts = [
            "European Union trade policy and international commerce regulations",
            "Environmental protection and climate change legislation",
            "Healthcare systems and medical research funding",
            "Agricultural subsidies and farming regulations",
            "Digital privacy and data protection laws"
        ]
        
        print(f"\nğŸ§ª Î”ÎŸÎšÎ™ÎœÎ— CLASSIFICATION (Default texts):")
        print("-" * 40)
        
        for i, text in enumerate(test_texts, 1):
            print(f"\n{i}. Query: {text[:50]}...")
            
            result = classifier.classify_text(text, top_k=5)
            
            print(f"   â±ï¸  Processing time: {result.processing_time:.3f}s")
            print(f"   ğŸ¯ Top-5 concepts:")
            
            for j, (concept_id, title, score) in enumerate(result.predicted_concepts, 1):
                print(f"      {j}. {title} (ID: {concept_id}) - Score: {score:.4f}")
    
    else:
        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· PDF Î±ÏÏ‡ÎµÎ¯Ï‰Î½
        print(f"\nğŸ“š Î¦ÏŒÏÏ„Ï‰ÏƒÎ· PDF Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î±Ï€ÏŒ TEST_LEGISLATIONS...")
        test_samples = load_test_pdfs(test_pdfs_dir, max_files=3)  # Î ÎµÏÎ¹Î¿ÏÎ¯Î¶Î¿Ï…Î¼Îµ ÏƒÎµ 3 Î³Î¹Î± demo
        
        if not test_samples:
            print("âŒ Î”ÎµÎ½ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ PDF Î±ÏÏ‡ÎµÎ¯Î±")
            return
        
        print(f"\nğŸ§ª Î”ÎŸÎšÎ™ÎœÎ— CLASSIFICATION (PDF Legislations):")
        print("-" * 50)
        
        for i, sample in enumerate(test_samples, 1):
            filename = sample['filename']
            text = sample['text']
            word_count = sample['text_length']
            
            print(f"\n{i}. PDF: {filename}")
            print(f"   ğŸ“Š ÎœÎ­Î³ÎµÎ¸Î¿Ï‚: {word_count:,} Î»Î­Î¾ÎµÎ¹Ï‚")
            
            # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± Ï€ÏÏÏ„Î± 200 Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ Î³Î¹Î± preview
            preview = text[:200].replace('\n', ' ').replace('\r', ' ')
            preview = re.sub(r'\s+', ' ', preview).strip()
            print(f"   ğŸ“ Preview: {preview}...")
            
            # Classification
            start_time = datetime.now()
            result = classifier.classify_text(text, top_k=10)
            
            print(f"   â±ï¸  Processing time: {result.processing_time:.3f}s")
            print(f"   ğŸ¯ Top-10 concepts:")
            
            for j, (concept_id, title, score) in enumerate(result.predicted_concepts, 1):
                # Color coding Î³Î¹Î± scores
                if score > 0.3:
                    color = "ğŸŸ¢"
                elif score > 0.1:
                    color = "ğŸŸ¡"
                else:
                    color = "ğŸ”´"
                
                print(f"      {j:2d}. {color} {title}")
                print(f"          ID: {concept_id} | Score: {score:.4f}")
            
            print(f"\n   ğŸ’¡ ÎŸÎ¹ Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎµÏ‚ Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î³Î¹Î± {filename}:")
            top_3 = result.predicted_concepts[:3]
            for rank, (cid, title, score) in enumerate(top_3, 1):
                print(f"      #{rank}: {title} ({score:.3f})")
    
    # System info
    info = classifier.get_system_info()
    print(f"\nğŸ“Š SYSTEM INFO:")
    print("-" * 30)
    print(f"   â€¢ Loaded concepts: {info['loaded_concepts']:,}")
    print(f"   â€¢ Vocabulary size: {info['vocabulary_size']:,}")
    print(f"   â€¢ TF-IDF matrix: {info['tfidf_matrix_shape']}")
    print(f"   â€¢ Total queries processed: {info['classification_stats']['total_queries']}")
    
    if info['classification_stats']['total_queries'] > 0:
        avg_time = info['classification_stats']['avg_processing_time']
        print(f"   â€¢ Average processing time: {avg_time:.3f}s")
    
    print(f"\nâœ… Demo Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
    print(f"ğŸ“‹ Î“Î¹Î± Ï€Î¹Î¿ Î»ÎµÏ€Ï„Î¿Î¼ÎµÏÎ® evaluation, Ï„ÏÎ­Î¾Ï„Îµ: python evaluate_classifier.py")
    print(f"ğŸ® Î“Î¹Î± interactive testing, Ï„ÏÎ­Î¾Ï„Îµ: python demo_classifier.py")

if __name__ == "__main__":
    main()
