#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Batch Summary Creator - Î”Î·Î¼    print(f"\nğŸ“Š Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ‘:")
    print(f"   â€¢ Concepts Ï€ÏÎ¿Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±: {len(concept_ids):,}")
    print(f"   â€¢ Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚: {len(concept_ids) * 3.3 / 60:.1f} Î»ÎµÏ€Ï„Î¬")
    
    # Î‘ÎºÏÎ¹Î²Î­ÏƒÏ„ÎµÏÎ¿Ï‚ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎºÏŒÏƒÏ„Î¿Ï…Ï‚
    # gpt-4o-mini: $0.150/1M input tokens, $0.600/1M output tokens
    avg_input_tokens = 1600   # Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿ ÏƒÏ„Î± logs
    avg_output_tokens = 150   # ~100 words = ~150 tokens
    
    total_input_tokens = len(concept_ids) * avg_input_tokens
    total_output_tokens = len(concept_ids) * avg_output_tokens
    
    input_cost = (total_input_tokens / 1_000_000) * 0.150
    output_cost = (total_output_tokens / 1_000_000) * 0.600
    total_cost = input_cost + output_cost
    
    print(f"   â€¢ Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ OpenAI:")
    print(f"     - Input tokens: {total_input_tokens:,} Ã— $0.150/1M = ${input_cost:.3f}")
    print(f"     - Output tokens: {total_output_tokens:,} Ã— $0.600/1M = ${output_cost:.3f}")
    print(f"     - ğŸ’° Î£Î¥ÎÎŸÎ›ÎŸ: ${total_cost:.2f}")Î³Î¯Î± Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÏ‰Î½
"""

import os
import time
import json
from datetime import datetime
from eurovoc_summary_generator import EurovocSummaryGenerator

# Pricing Î³Î¹Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± ($ per 1M tokens)
MODEL_PRICING = {
    'gpt-4o-mini': {
        'input': 0.150,
        'output': 0.600
    },
    'gpt-3.5-turbo': {
        'input': 0.500,
        'output': 1.500
    },
    'gpt-4-turbo': {
        'input': 10.000,
        'output': 30.000
    },
    'gpt-4': {
        'input': 30.000,
        'output': 60.000
    }
}

def estimate_tokens(text, is_output=False):
    """Î•ÎºÏ„Î¹Î¼Î¬ Ï„Î¿Î½ Î±ÏÎ¹Î¸Î¼ÏŒ tokens ÏƒÎµ Î­Î½Î± ÎºÎµÎ¯Î¼ÎµÎ½Î¿."""
    # Î‘Ï€Î»Î® ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ·: ~4 Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ = 1 token
    # Î“Î¹Î± output ÎµÎ¯Î½Î±Î¹ Ï€Î¹Î¿ ÏƒÏ…Î¼Ï€Î±Î³Î­Ï‚
    chars_per_token = 3.5 if is_output else 4
    return int(len(text) / chars_per_token)

def calculate_request_cost(prompt, response, model):
    """Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ Î¼Î¹Î±Ï‚ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î·Ï‚ request."""
    if model not in MODEL_PRICING:
        return 0.0
    
    input_tokens = estimate_tokens(prompt, is_output=False)
    output_tokens = estimate_tokens(response, is_output=True)
    
    pricing = MODEL_PRICING[model]
    input_cost = (input_tokens / 1_000_000) * pricing['input']
    output_cost = (output_tokens / 1_000_000) * pricing['output']
    
    return {
        'input_tokens': input_tokens,
        'output_tokens': output_tokens,
        'input_cost': input_cost,
        'output_cost': output_cost,
        'total_cost': input_cost + output_cost
    }

def save_cost_report(run_data, cost_summary):
    """Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ Î±Î½Î±Ï†Î¿ÏÎ¬ ÎºÏŒÏƒÏ„Î¿Ï…Ï‚."""
    cost_file = os.path.join(os.path.dirname(__file__), 'cost_tracking.json')
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    if os.path.exists(cost_file):
        with open(cost_file, 'r', encoding='utf-8') as f:
            cost_data = json.load(f)
    else:
        cost_data = {
            'total_runs': 0,
            'total_cost': 0.0,
            'total_concepts': 0,
            'total_tokens': {'input': 0, 'output': 0},
            'runs': []
        }
    
    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î½Î­Î¿Ï… run
    cost_data['runs'].append(run_data)
    cost_data['total_runs'] += 1
    cost_data['total_cost'] += cost_summary['total_cost']
    cost_data['total_concepts'] += cost_summary['concepts_processed']
    cost_data['total_tokens']['input'] += cost_summary['total_input_tokens']
    cost_data['total_tokens']['output'] += cost_summary['total_output_tokens']
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
    with open(cost_file, 'w', encoding='utf-8') as f:
        json.dump(cost_data, f, ensure_ascii=False, indent=2)
    
    return cost_file

def create_multiple_summaries():
    """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÎ¹Ï‚ Î³Î¹Î± Ï€Î¿Î»Î»Î±Ï€Î»Î¬ concepts Î® ÏŒÎ»Î± Ï„Î± concepts."""
    
    print("ğŸ“š BATCH SUMMARY CREATOR")
    print("="*50)
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± generator
    generator = EurovocSummaryGenerator()
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    print("ğŸ“¥ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
    generator.load_data()
    
    print(f"\nğŸ“Š Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ‘ VOCABULARY:")
    print(f"   â€¢ Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚: {len(generator.vocabulary):,}")
    print(f"   â€¢ Concepts Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î±: {len(generator.enhanced_mapping):,}")
    
    # Î•Ï€Î¹Î»Î¿Î³Î­Ï‚ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚
    print("\nğŸ¯ Î•Î Î™Î›ÎŸÎ“Î•Î£ Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“Î™Î‘Î£:")
    print("1. Specific concepts (sample list)")
    print("2. ÎŸÎ›Î‘ Ï„Î± Eurovoc concepts (7,384 concepts)")
    print("3. First 100 concepts (Î³Î¹Î± Î´Î¿ÎºÎ¹Î¼Î®)")
    print("4. Custom word count per concept")
    print("4. Concepts Î±Ï€ÏŒ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±")
    
    # Production ready - Î¼Ï€Î¿ÏÎµÎ¯Ï‚ Î½Î± Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ ÎµÎ´Ï
    choice = "2"  # Î‘Î»Î»Î±Î¾Îµ ÏƒÎµ "1", "2", "3" Î® "4"
    
    if choice == "1":
        # Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± concepts Î³Î¹Î± cost tracking test
        concept_ids = [
            "1033",  # test concept 1
            "1034",  # test concept 2
        ]
    elif choice == "2":
        # ÎŸÎ›Î‘ Ï„Î± concepts
        concept_ids = list(generator.enhanced_mapping.keys())
        print(f"ğŸš€ Î˜Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ¿Ï…Î¼Îµ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÎ¹Ï‚ Î³Î¹Î± ÎŸÎ›Î‘ Ï„Î± {len(concept_ids):,} concepts!")
        print("âš ï¸  Î‘Ï…Ï„ÏŒ Î¸Î± Ï€Î¬ÏÎµÎ¹ Ï€Î¿Î»Ï Ï‡ÏÏŒÎ½Î¿ ÎºÎ±Î¹ ÎºÏŒÏƒÏ„Î¿Ï‚ OpenAI!")
        
    elif choice == "3":
        # Î ÏÏÏ„Î± 100 Î³Î¹Î± Î´Î¿ÎºÎ¹Î¼Î®
        concept_ids = list(generator.enhanced_mapping.keys())[:100]
        print(f"ğŸ§ª Î”ÎŸÎšÎ™ÎœÎ—: Î˜Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ¿Ï…Î¼Îµ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î± Ï€ÏÏÏ„Î± {len(concept_ids)} concepts")
        
    elif choice == "4":
        # Custom word count per concept
        max_words = input("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î»Î­Î¾ÎµÏ‰Î½ Î±Î½Î¬ concept (default: 150): ").strip()
        max_words = int(max_words) if max_words.isdigit() else 150
        
        concept_ids = [
            "5132",  # health control
            "1030",  # plant life
            "192",   # agricultural statistics
            "4041",  # energy policy
            "6066",  # social security
        ]
        print(f"ğŸ¯ Custom test Î¼Îµ {max_words} Î»Î­Î¾ÎµÎ¹Ï‚ Î±Î½Î¬ concept")
        
    else:
        print("âŒ ÎœÎ· Î­Î³ÎºÏ…ÏÎ· ÎµÏ€Î¹Î»Î¿Î³Î®!")
        return
    
    # Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï€Î±ÏÎ±Î¼Î­Ï„ÏÏ‰Î½
    max_vocabulary_words = 150  # Default
    if choice == "4":
        max_vocabulary_words = max_words if 'max_words' in locals() else 150
    
    print(f"\nï¿½ Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ‘:")
    print(f"   â€¢ Concepts Ï€ÏÎ¿Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±: {len(concept_ids):,}")
    print(f"   â€¢ Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚: {len(concept_ids) * 3 / 60:.1f} Î»ÎµÏ€Ï„Î¬")
    print(f"   â€¢ Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ OpenAI: ~${len(concept_ids) * 0.002:.2f}")
    
    # Î•Ï€Î¹Î²ÎµÎ²Î±Î¯Ï‰ÏƒÎ·
    print(f"\nâš ï¸  Î Î¡ÎŸÎ£ÎŸÎ§Î—: Î‘Ï…Ï„ÏŒ Î¸Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÎ¹ {len(concept_ids)} Î±ÏÏ‡ÎµÎ¯Î± JSON!")
    confirmation = input("Î£Ï…Î½Î­Ï‡ÎµÎ¹Î±; (y/N): ").lower().strip()
    
    if confirmation != 'y':
        print("âŒ Î‘ÎºÏ…ÏÏÎ¸Î·ÎºÎµ Î±Ï€ÏŒ Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î·")
        return
    
    # Batch ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼Îµ advanced tracking
    print(f"\nğŸš€ Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· batch ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚...")
    print(f"ğŸ“Š Progress tracking ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿")
    print(f"ğŸ’° Cost tracking ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿")
    
    # Custom batch function Î¼Îµ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ tracking
    successful = 0
    failed = 0
    skipped = 0
    start_time = time.time()
    
    # Cost tracking
    total_cost = 0.0
    total_input_tokens = 0
    total_output_tokens = 0
    cost_details = []
    
    for i, concept_id in enumerate(concept_ids, 1):
        try:
            # Progress update ÎºÎ¬Î¸Îµ 10 concepts
            if i % 10 == 0 or i == 1:
                elapsed = time.time() - start_time
                rate = i / elapsed * 60 if elapsed > 0 else 0
                eta = (len(concept_ids) - i) / (rate / 60) if rate > 0 else 0
                print(f"ğŸ“ˆ Progress: {i:,}/{len(concept_ids):,} ({i/len(concept_ids)*100:.1f}%) | "
                      f"Rate: {rate:.1f}/min | ETA: {eta/60:.1f}h")
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿
            output_file = os.path.join(generator.output_dir, f"concept_{concept_id}_summary.json")
            if os.path.exists(output_file):
                print(f"â­ï¸  Skipping {concept_id} (already exists)")
                skipped += 1
                continue
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚
            concept_data = generator.enhanced_mapping[concept_id]
            related_words, word_stats = generator.get_related_vocabulary_words(concept_id, max_vocabulary_words)
            prompt = generator.create_llm_prompt(concept_data, related_words, word_stats, 'medium')
            
            result = generator.create_summary_for_concept(
                concept_id=concept_id,
                summary_length='medium',
                model='gpt-4o-mini',
                max_words=max_vocabulary_words
            )
            
            # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÎºÏŒÏƒÏ„Î¿Ï…Ï‚ Î³Î¹Î± Î±Ï…Ï„Î® Ï„Î·Î½ request
            request_cost = calculate_request_cost(prompt, result['summary'], 'gpt-4o-mini')
            total_cost += request_cost['total_cost']
            total_input_tokens += request_cost['input_tokens']
            total_output_tokens += request_cost['output_tokens']
            
            cost_details.append({
                'concept_id': concept_id,
                'concept_title': concept_data['title'],
                'cost': request_cost['total_cost'],
                'tokens': {
                    'input': request_cost['input_tokens'],
                    'output': request_cost['output_tokens']
                }
            })
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·
            generator.save_summary(result)
            successful += 1
            
            # Rate limiting
            time.sleep(2.0)
            
        except KeyboardInterrupt:
            print(f"\nğŸ›‘ Î”Î¹Î±ÎºÎ¿Ï€Î® Î±Ï€ÏŒ Ï‡ÏÎ®ÏƒÏ„Î· ÏƒÏ„Î¿ concept {i}/{len(concept_ids)}")
            break
        except Exception as e:
            print(f"âŒ Error processing {concept_id}: {str(e)}")
            failed += 1
            continue
    
    # Î¤ÎµÎ»Î¹ÎºÎ¬ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Îµ cost tracking
    total_time = time.time() - start_time
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± cost summary
    cost_summary = {
        'total_cost': total_cost,
        'concepts_processed': successful,
        'concepts_skipped': skipped,
        'concepts_failed': failed,
        'total_input_tokens': total_input_tokens,
        'total_output_tokens': total_output_tokens,
        'cost_per_concept': total_cost / successful if successful > 0 else 0
    }
    
    # Î”ÎµÎ´Î¿Î¼Î­Î½Î± run
    run_data = {
        'timestamp': datetime.now().isoformat(),
        'model_used': 'gpt-4o-mini',
        'duration_minutes': total_time / 60,
        'concepts_requested': len(concept_ids),
        'concepts_processed': successful,
        'concepts_skipped': skipped,
        'concepts_failed': failed,
        'cost_summary': cost_summary,
        'cost_details': cost_details[:10]  # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¼ÏŒÎ½Î¿ Ï„Ï‰Î½ Ï€ÏÏÏ„Ï‰Î½ 10 Î³Î¹Î± Î¼Î­Î³ÎµÎ¸Î¿Ï‚
    }
    
    print(f"\nâœ… BATCH ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ•!")
    print(f"ğŸ“Š Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ‘:")
    print(f"   â€¢ Î•Ï€Î¹Ï„Ï…Ï‡Î®Ï‚: {successful:,}")
    print(f"   â€¢ Î Î±ÏÎ±Î»Î®Ï†Î¸Î·ÎºÎ±Î½: {skipped:,}")
    print(f"   â€¢ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î±: {failed:,}")
    print(f"   â€¢ Î£Ï…Î½Î¿Î»Î¹ÎºÏŒÏ‚ Ï‡ÏÏŒÎ½Î¿Ï‚: {total_time/60:.1f} Î»ÎµÏ€Ï„Î¬")
    print(f"   â€¢ ÎœÎ­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚: {total_time/max(successful+failed,1):.1f} Î´ÎµÏ…Ï„/concept")
    
    print(f"\nğŸ’° ÎšÎŸÎ£Î¤ÎŸÎ£ Î‘ÎÎ‘Î›Î¥Î£Î—:")
    print(f"   â€¢ Î£Ï…Î½Î¿Î»Î¹ÎºÏŒ ÎºÏŒÏƒÏ„Î¿Ï‚: ${total_cost:.4f}")
    print(f"   â€¢ ÎšÏŒÏƒÏ„Î¿Ï‚ Î±Î½Î¬ concept: ${cost_summary['cost_per_concept']:.6f}")
    print(f"   â€¢ Input tokens: {total_input_tokens:,}")
    print(f"   â€¢ Output tokens: {total_output_tokens:,}")
    print(f"   â€¢ Total tokens: {total_input_tokens + total_output_tokens:,}")
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· cost report
    if successful > 0:
        cost_file = save_cost_report(run_data, cost_summary)
        print(f"   â€¢ ğŸ“„ Cost report Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ: {cost_file}")
    
    print(f"\nğŸ“ Î‘ÏÏ‡ÎµÎ¯Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿: {generator.output_dir}")

if __name__ == "__main__":
    create_multiple_summaries()
