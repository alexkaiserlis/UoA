#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Eurovision Concept Analysis Tool
===============================
Î‘Î½Î±Î»ÏÎµÎ¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… ÏƒÏ…Î½Î´Î­Î¿Î½Ï„Î±Î¹ Î¼Îµ Î­Î½Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Eurovision concept ID.
"""

import json
import os
from collections import Counter
from datetime import datetime

def analyze_concept_words(concept_id, save_to_file=True):
    """
    Î‘Î½Î±Î»ÏÎµÎ¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ Ï„Î¿ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Eurovision concept.
    
    Args:
        concept_id (str): Î¤Î¿ Eurovision concept ID Ï€ÏÎ¿Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·
        save_to_file (bool): Î‘Î½ True, Î±Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± ÏƒÎµ Î±ÏÏ‡ÎµÎ¯Î¿
    """
    
    print(f"ğŸ” Î‘ÎÎ‘Î›Î¥Î£Î— EUROVISION CONCEPT: {concept_id}")
    print("="*60)
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Eurovision mappings Î³Î¹Î± Ï„Î¿Î½ Ï„Î¯Ï„Î»Î¿
    eurovoc_path = 'data/eurovoc_id_title_mappings.json'
    if not os.path.exists(eurovoc_path):
        print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿: {eurovoc_path}")
        return
    
    with open(eurovoc_path, 'r', encoding='utf-8') as f:
        eurovoc_mappings = json.load(f)
    
    concept_title = eurovoc_mappings.get(concept_id, "UNKNOWN")
    print(f"ğŸ“‹ Concept Title: \"{concept_title}\"")
    print(f"ğŸ†” Concept ID: {concept_id}")
    print()
    
    # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· ÎºÏÏÎ¹Î¿Ï… vocabulary
    vocab_path = 'data/eurlex_legal_vocabulary.json'
    if not os.path.exists(vocab_path):
        print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿: {vocab_path}")
        return
    
    print("â³ Î¦ÏŒÏÏ„Ï‰ÏƒÎ· vocabulary... (Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€Î¬ÏÎµÎ¹ Î»Î¯Î³Î¿)")
    with open(vocab_path, 'r', encoding='utf-8') as f:
        vocabulary = json.load(f)
    
    print(f"âœ… Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(vocabulary):,} Î»Î­Î¾ÎµÎ¹Ï‚")
    print()
    
    # Î•ÏÏÎµÏƒÎ· Î»Î­Î¾ÎµÏ‰Î½ Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ Ï„Î¿ concept
    matching_words = []
    
    print("ğŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î»Î­Î¾ÎµÏ‰Î½ Î¼Îµ Ï„Î¿ concept...")
    for word, concepts in vocabulary.items():
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï„Î¿ concept_id Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î± concepts Î±Ï…Ï„Î®Ï‚ Ï„Î·Ï‚ Î»Î­Î¾Î·Ï‚
        for concept in concepts:
            if concept.get('id') == concept_id:
                matching_words.append(word)
                break
    
    # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
    total_words = len(matching_words)
    word_lengths = [len(word) for word in matching_words]
    
    results = {
        'analysis_info': {
            'concept_id': concept_id,
            'concept_title': concept_title,
            'analysis_date': datetime.now().isoformat(),
            'total_vocabulary_size': len(vocabulary)
        },
        'statistics': {
            'total_matching_words': total_words,
            'percentage_of_vocabulary': (total_words / len(vocabulary)) * 100 if vocabulary else 0,
            'word_length_stats': {
                'min_length': min(word_lengths) if word_lengths else 0,
                'max_length': max(word_lengths) if word_lengths else 0,
                'avg_length': sum(word_lengths) / len(word_lengths) if word_lengths else 0
            }
        },
        'word_analysis': {
            'all_words': sorted(matching_words),
            'word_frequency_by_length': dict(Counter(word_lengths)) if word_lengths else {},
            'sample_words': {
                'shortest': [w for w in matching_words if len(w) == min(word_lengths)] if word_lengths else [],
                'longest': [w for w in matching_words if len(w) == max(word_lengths)] if word_lengths else [],
                'most_common_length': sorted(matching_words, key=len)[len(matching_words)//2:len(matching_words)//2+5] if matching_words else []
            }
        }
    }
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    print("ğŸ“Š Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘ Î‘ÎÎ‘Î›Î¥Î£Î—Î£:")
    print("-" * 40)
    print(f"ğŸ¯ Concept: {concept_id} - \"{concept_title}\"")
    print(f"ğŸ“ Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚: {total_words:,}")
    print(f"ğŸ“ˆ Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ vocabulary: {results['statistics']['percentage_of_vocabulary']:.2f}%")
    
    if word_lengths:
        print(f"ğŸ“ ÎœÎ®ÎºÎ¿Ï‚ Î»Î­Î¾ÎµÏ‰Î½:")
        print(f"   â€¢ Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î¿: {results['statistics']['word_length_stats']['min_length']} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚")
        print(f"   â€¢ ÎœÎ­Î³Î¹ÏƒÏ„Î¿: {results['statistics']['word_length_stats']['max_length']} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚") 
        print(f"   â€¢ ÎœÎ­ÏƒÎ¿Ï‚ ÏŒÏÎ¿Ï‚: {results['statistics']['word_length_stats']['avg_length']:.1f} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚")
    
    print()
    print("ğŸ“‹ Î”Î•Î™Î“ÎœÎ‘ Î›Î•ÎÎ•Î©Î:")
    print("-" * 40)
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î´ÎµÎ¯Î³Î¼Î±Ï„Î¿Ï‚ Î»Î­Î¾ÎµÏ‰Î½
    if matching_words:
        sample_size = min(20, len(matching_words))
        sample_words = sorted(matching_words)[:sample_size]
        
        for i, word in enumerate(sample_words, 1):
            print(f"{i:2d}. {word}")
        
        if len(matching_words) > sample_size:
            print(f"... ÎºÎ±Î¹ {len(matching_words) - sample_size:,} Î±ÎºÏŒÎ¼Î· Î»Î­Î¾ÎµÎ¹Ï‚")
    else:
        print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î»Î­Î¾ÎµÎ¹Ï‚ Î³Î¹Î± Î±Ï…Ï„ÏŒ Ï„Î¿ concept!")
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÎµ Î±ÏÏ‡ÎµÎ¯Î¿
    if save_to_file and matching_words:
        output_filename = f"concept_{concept_id}_analysis.json"
        output_path = os.path.join('data', output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print()
        print(f"ğŸ’¾ Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿: {output_path}")
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ readable summary
        summary_filename = f"concept_{concept_id}_summary.txt"
        summary_path = os.path.join('data', summary_filename)
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"EUROVISION CONCEPT ANALYSIS\n")
            f.write(f"{'='*50}\n")
            f.write(f"Concept ID: {concept_id}\n")
            f.write(f"Concept Title: {concept_title}\n")
            f.write(f"Analysis Date: {datetime.now().strftime('%d/%m/%Y %H:%M')}\n")
            f.write(f"\nSTATISTICS:\n")
            f.write(f"{'='*30}\n")
            f.write(f"Total matching words: {total_words:,}\n")
            f.write(f"Percentage of vocabulary: {results['statistics']['percentage_of_vocabulary']:.2f}%\n")
            if word_lengths:
                f.write(f"Min word length: {results['statistics']['word_length_stats']['min_length']} chars\n")
                f.write(f"Max word length: {results['statistics']['word_length_stats']['max_length']} chars\n")
                f.write(f"Avg word length: {results['statistics']['word_length_stats']['avg_length']:.1f} chars\n")
            
            f.write(f"\nALL MATCHING WORDS:\n")
            f.write(f"{'='*30}\n")
            for i, word in enumerate(sorted(matching_words), 1):
                f.write(f"{i:4d}. {word}\n")
        
        print(f"ğŸ“„ Readable summary Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÏƒÏ„Î¿: {summary_path}")
    
    return results

def main():
    """ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î¼Îµ Î¼ÎµÎ½Î¿Ï ÎµÏ€Î¹Î»Î¿Î³ÏÎ½."""
    
    print("ğŸ‡ªğŸ‡º EUROVISION CONCEPT ANALYZER")
    print("="*50)
    print()
    
    # Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î± concepts Î³Î¹Î± Î´Î¿ÎºÎ¹Î¼Î®
    suggested_concepts = [
        ("1309", "import"),
        ("889", "State aid"), 
        ("192", "health control"),
        ("1318", "Germany"),
        ("2771", "originating product")
    ]
    
    print("ğŸ¯ Î Î¡ÎŸÎ¤Î•Î™ÎÎŸÎœÎ•ÎÎ‘ CONCEPTS Î“Î™Î‘ Î”ÎŸÎšÎ™ÎœÎ—:")
    print("-" * 40)
    for i, (concept_id, title) in enumerate(suggested_concepts, 1):
        print(f"{i}. {concept_id} - \"{title}\"")
    
    print()
    choice = input("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ concept (1-5) Î® ÎµÎ¹ÏƒÎ¬Î³ÎµÏ„Îµ Î´Î¹ÎºÏŒ ÏƒÎ±Ï‚ ID: ").strip()
    
    if choice.isdigit() and 1 <= int(choice) <= 5:
        concept_id = suggested_concepts[int(choice)-1][0]
    else:
        concept_id = choice
    
    print()
    analyze_concept_words(concept_id)

if __name__ == "__main__":
    main()
